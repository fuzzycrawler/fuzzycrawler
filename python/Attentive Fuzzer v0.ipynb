{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "superior-binary",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Piyush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Piyush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Piyush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "import numpy as np\n",
    "import keras.backend.tensorflow_backend as backend\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Activation, Flatten, Input, Lambda\n",
    "from tensorflow.keras.layers import  RepeatVector, TimeDistributed, GlobalMaxPooling1D, Embedding, Permute\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from collections import deque\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "preceding-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grammar1 to Grammar5 files stored in all_grammar_inputs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "royal-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Stub.Stub import StubSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "imposed-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grammar_lib.testCaseModifier import GCheckModifier\n",
    "from grammar_lib.SQLChecker import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "american-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"grammar_lib/all_grammar_inputs.txt\") as file:\n",
    "    all_grammar_inputs = [line.strip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "handy-geology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = all_grammar_inputs.copy()\n",
    "\n",
    "sent_processed = []\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "for input_str in sent:\n",
    "    input_str = str(input_str)\n",
    "    input_str = input_str.lower()\n",
    "    input_str = input_str.strip()\n",
    "    sent_processed.append(nltk.word_tokenize(input_str))\n",
    "    # sent_processed.append(tokenizer.tokenize(input_str))\n",
    "    \n",
    "all_vocab = [v_w for v in sent_processed for v_w in v]\n",
    "\n",
    "v_count = dict(Counter(all_vocab))\n",
    "v_count = dict(sorted(v_count.items(), key=lambda item: item[1], reverse=True))\n",
    "all_vocab = list(v_count.keys())\n",
    "\n",
    "all_vocab.sort()\n",
    "\n",
    "ind_list = list(range(1, len(all_vocab)+1))\n",
    "\n",
    "word2ind = dict(zip(all_vocab, ind_list))\n",
    "ind2word = dict(zip(ind_list, all_vocab))\n",
    "\n",
    "word2ind['<EOS>'] = 0\n",
    "ind2word[0] = '<EOS>'\n",
    "\n",
    "all_vocab = ['<EOS>']+all_vocab\n",
    "\n",
    "VOCAB_SIZE = len(all_vocab)\n",
    "\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "forward-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gmod = GCheckModifier()\n",
    "# gparse = parser()\n",
    "\n",
    "# str_test = \"('  UNION select NULL email from DUAL #\"#all_grammar_inputs[1000]\n",
    "# print(str_test)\n",
    "# for_parsing = gmod.grammarchecker(str_test) \n",
    "# print(for_parsing)\n",
    "# gparse.main(for_parsing) # 1 for failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "funny-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISCOUNT = 0.99\n",
    "REPLAY_MEMORY_SIZE = 5_000  # last steps to keep for model training\n",
    "MIN_REPLAY_MEMORY_SIZE = 150 \n",
    "MINIBATCH_SIZE = 128\n",
    "UPDATE_TARGET_EVERY = 5\n",
    "MODEL_NAME = 'RLFuzzv0.1'\n",
    "MIN_REWARD = -200\n",
    "MAX_LENGTH = 11 # including EOS\n",
    "\n",
    "EPISODES = 1_000\n",
    "\n",
    "epsilon = 1\n",
    "EPSILON_DECAY = 0.99975\n",
    "MIN_EPSILON = 0.001\n",
    "\n",
    "AGGREGATE_STATS_EVERY = 100  # episodes\n",
    "\n",
    "# succ = [word2ind[s] for s in \"( ' OR 1 = 1 ; -- )\".lower().split()]+[0, 0] # maintain max_length & EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stuck-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_test = [] # store compatible length grammar based init (generation) test strings\n",
    "for sent in sent_processed:\n",
    "    if len(sent)<=MAX_LENGTH-1:\n",
    "        loaded_test.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "loved-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eos_and_ind(sampled_list: list, ind: bool = False):\n",
    "    if ind:\n",
    "        eos_token = 0\n",
    "    else:\n",
    "        eos_token = \"<EOS>\"\n",
    "    clip_ind = sampled_list.index(eos_token)\n",
    "    if clip_ind < MAX_LENGTH-1:\n",
    "        clip_ind_rem = MAX_LENGTH-clip_ind\n",
    "        sampled_list = sampled_list[:clip_ind]+[eos_token]*clip_ind_rem # slower than if\n",
    "    assert len(sampled_list) == MAX_LENGTH\n",
    "    if ind:\n",
    "        return sampled_list\n",
    "    return [word2ind[s] for s in sampled_list]\n",
    "\n",
    "def init_string_list():\n",
    "    gram_gen_str = loaded_test[random.randint(0, len(loaded_test))]\n",
    "    sampled_list = gram_gen_str+(MAX_LENGTH-len(gram_gen_str))*['<EOS>']\n",
    "    # sampled_list = list(random.sample(all_vocab, MAX_LENGTH-1))+['<EOS>']\n",
    "    return eos_and_ind(sampled_list)\n",
    "\n",
    "def mutate_string_list(seed: list, pos: int = None, vocab: int = None):\n",
    "    if vocab is None:\n",
    "        vocab_str = random.sample(all_vocab, 1)[0]\n",
    "        vocab = word2ind[vocab_str]\n",
    "    if pos is None:\n",
    "        pos = random.randint(0, MAX_LENGTH-2) # MAX_LENGTH-2 inclusive\n",
    "    if pos != MAX_LENGTH-1: # should never replace EOS\n",
    "        seed[pos] = vocab\n",
    "    return eos_and_ind(seed, ind=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "outside-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLFuzz:\n",
    "    def __init__(self, rewarding=None):\n",
    "        if rewarding is None:\n",
    "            self.init_string = init_string_list() # always as index\n",
    "        else:\n",
    "            self.init_string = rewarding.copy()\n",
    "        self.seed_str = self.init_string.copy()\n",
    "        self.last_str = self.init_string.copy()\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'\\nOrg: \\n{\" \".join([ind2word[s] for s in self.init_string])}\\n Current seed string: \\n{\" \".join([ind2word[s] for s in self.seed_str])}'\n",
    "\n",
    "    def action(self, pos, vocab):\n",
    "        self.last_str = self.seed_str.copy()\n",
    "        self.seed_str = mutate_string_list(seed=self.seed_str, pos=pos, vocab=vocab)\n",
    "\n",
    "class RLFuzzEnv:\n",
    "    MUTATION_PENALTY = 1\n",
    "    SAME_STRING_PENALTY = 10 # eos & grammar related\n",
    "    PARSER_PENALTY = 20\n",
    "    SUCCESS_REWARD = 1000\n",
    "    ACTION_SPACE_SIZE_POS = MAX_LENGTH\n",
    "    ACTION_SPACE_SIZE_VOCAB = VOCAB_SIZE\n",
    "\n",
    "    def reset(self, rewarding=None):\n",
    "        self.session = StubSession()\n",
    "        self.last_status = 0\n",
    "        self.fuzzer = RLFuzz(rewarding)\n",
    "        self.episode_step = 0\n",
    "        observation = self.fuzzer.init_string\n",
    "        \n",
    "        self.gmod = GCheckModifier()\n",
    "        self.gparse = parser()\n",
    "        \n",
    "        return observation\n",
    "\n",
    "    def step(self, action_pos, action_vocab):       \n",
    "        self.episode_step += 1\n",
    "        self.fuzzer.action(action_pos, action_vocab)\n",
    "        new_observation = self.fuzzer.seed_str\n",
    "        \n",
    "        eos_index = new_observation.index(0)\n",
    "        new_observation_ = new_observation[:eos_index]\n",
    "        username_rl = \" \".join([ind2word[s] for s in new_observation_])\n",
    "                \n",
    "        eos_indexL = self.fuzzer.last_str.index(0)\n",
    "        new_observationL_ = self.fuzzer.last_str[:eos_indexL]\n",
    "        last_username_rl = \" \".join([ind2word[s] for s in new_observationL_])\n",
    "        \n",
    "        if len(username_rl.strip()) == 0 or last_username_rl==username_rl: # rudimentary\n",
    "#             print(f\"SAME_STRING_PENALTY @ {self.episode_step}: \", username_rl)\n",
    "            reward = -self.SAME_STRING_PENALTY\n",
    "        elif parser_failed: # parser\n",
    "#             print(f\"PARSER_PENALTY @ {self.episode_step}: \", username_rl)\n",
    "            reward = -self.PARSER_PENALTY\n",
    "        else: # check via website\n",
    "            if self.last_status == 1:\n",
    "                self.session.reset_session()\n",
    "\n",
    "            url=\"http://localhost/demo/example_mysql_injection_login.php\"\n",
    "            jsonFilePath = './Stub/conditions.json'\n",
    "            receive=self.session.s.get(url)\n",
    "            form_details,keys=self.session.preprocessing_Form_Fields(url)\n",
    "\n",
    "            values=[username_rl, \"RaNdOmStRiNg\"]\n",
    "            logindata=self.session.form_input_feeding(keys,values,form_details)\n",
    "            pass_Conditions, fail_Conditions = self.session.jsonReading(jsonFilePath)\n",
    "            status = self.session.validation(url, logindata, keys, pass_Conditions, fail_Conditions)\n",
    "            self.last_status = status\n",
    "\n",
    "            fuzzing_success = True if status==1 else False\n",
    "\n",
    "            if fuzzing_success:\n",
    "                print(f\"SUCCESS_REWARD @ {self.episode_step}: \", username_rl)\n",
    "                reward = self.SUCCESS_REWARD\n",
    "            else:\n",
    "    #             print(f\"MUTATION_PENALTY @ {self.episode_step}: \", username_rl)\n",
    "                reward = -self.MUTATION_PENALTY\n",
    "\n",
    "        done = False\n",
    "        if self.episode_step >= 100: #TODO: chk -- removed: @ SUCCESS_REWARD\n",
    "            done = True\n",
    "\n",
    "        return new_observation, reward, done\n",
    "\n",
    "# Agent class\n",
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.model = self.create_model()\n",
    "        self.target_model = self.create_model()\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        self.replay_memory = deque(maxlen=REPLAY_MEMORY_SIZE)\n",
    "        self.target_update_counter = 0\n",
    "\n",
    "        #self.tensorboard = ModifiedTensorBoard(log_dir=\"logs\\\\{}-{}\".format(MODEL_NAME, int(time.time())), profile_batch = 10000000)\n",
    "        #$REM\n",
    "        \n",
    "    def create_model(self):\n",
    "        inputs = Input(shape=(MAX_LENGTH,))\n",
    "\n",
    "        embed=Embedding(VOCAB_SIZE, 100)(inputs)\n",
    "\n",
    "        activations= keras.layers.GRU(250, return_sequences=True)(embed)\n",
    "\n",
    "        attention = TimeDistributed(Dense(1, activation='tanh'))(activations)\n",
    "        attention = Flatten()(attention)\n",
    "        attention = Activation('softmax')(attention)\n",
    "        attention = RepeatVector(250)(attention)\n",
    "        attention = Permute([2, 1])(attention)\n",
    "\n",
    "        sent_representation = keras.layers.multiply([activations, attention])\n",
    "        sent_representation = Lambda(lambda xin: K.sum(xin, axis=1))(sent_representation)\n",
    "\n",
    "        x_pos = Dense(32, activation=\"relu\")(sent_representation)\n",
    "        x_pos = Dropout(0.1)(x_pos)\n",
    "        x_pos = Dense(env.ACTION_SPACE_SIZE_POS, activation='linear', name='q_pos')(x_pos)\n",
    "\n",
    "        x_vocab = Dense(32, activation=\"relu\")(sent_representation)\n",
    "        x_vocab = Dropout(0.1)(x_vocab)\n",
    "        x_vocab = Dense(env.ACTION_SPACE_SIZE_VOCAB, activation='linear', name='q_vocab')(x_vocab)\n",
    "\n",
    "        model = keras.Model(inputs=inputs, outputs=[x_pos, x_vocab])\n",
    "        model.compile(loss=[\"mse\", \"mse\"], optimizer=Adam(lr=0.001), metrics=[\"accuracy\", \"accuracy\"])\n",
    "        return model\n",
    "\n",
    "    # (observation space, action_pos, action_vocab, reward, new observation space, done)\n",
    "    def update_replay_memory(self, transition):\n",
    "        self.replay_memory.append(transition)\n",
    "\n",
    "    def train(self, terminal_state, step):\n",
    "        if len(self.replay_memory) < MIN_REPLAY_MEMORY_SIZE:\n",
    "            return\n",
    "\n",
    "        # minibatch of random samples from memory replay table\n",
    "        minibatch = random.sample(self.replay_memory, MINIBATCH_SIZE)\n",
    "\n",
    "        # Get current states from minibatch, then query NN model for Q values\n",
    "        current_states = np.array([transition[0] for transition in minibatch])\n",
    "        current_qs_list = self.model.predict(current_states)\n",
    "        # print(current_qs_list[0].shape, current_qs_list[1].shape) # 64,11 & 64,60\n",
    "\n",
    "        # Get future states from minibatch, then query NN model for Q values\n",
    "        # When using target network, query it, otherwise main network should be queried\n",
    "        new_current_states = np.array([transition[-2] for transition in minibatch])\n",
    "        future_qs_list = self.target_model.predict(new_current_states)\n",
    "\n",
    "        X, y_pos, y_vocab = [], [], []\n",
    "\n",
    "        # Now we need to enumerate our batches\n",
    "        for index, (current_state, action_pos, action_vocab, reward, new_current_state, done) in enumerate(minibatch):\n",
    "\n",
    "            # If not a terminal state, get new q from future states, otherwise set it to 0\n",
    "            # almost like with Q Learning, but we use just part of equation here\n",
    "            if not done:\n",
    "                max_future_q_pos = np.max(future_qs_list[0][index])\n",
    "                new_q_pos = reward + DISCOUNT * max_future_q_pos\n",
    "                \n",
    "                max_future_q_vocab = np.max(future_qs_list[1][index])\n",
    "                new_q_vocab = reward + DISCOUNT * max_future_q_vocab\n",
    "            else:\n",
    "                new_q_pos = reward\n",
    "                new_q_vocab = reward\n",
    "\n",
    "            # Update Q value for given state\n",
    "            current_qs_pos = current_qs_list[0][index]\n",
    "            current_qs_pos[action_pos] = new_q_pos\n",
    "            \n",
    "            current_qs_vocab = current_qs_list[1][index]\n",
    "            current_qs_vocab[action_vocab] = new_q_vocab\n",
    "\n",
    "            # And append to our training data\n",
    "            X.append(current_state)\n",
    "            y_pos.append(current_qs_pos)\n",
    "            y_vocab.append(current_qs_vocab)\n",
    "\n",
    "        # Fit on all samples as one batch, log only on terminal state\n",
    "        self.model.fit(np.array(X), [y_pos, y_vocab], batch_size=MINIBATCH_SIZE, verbose=0, \n",
    "                       shuffle=False if terminal_state else None)\n",
    "        #$REM: ,callbacks=[self.tensorboard] \n",
    "\n",
    "        # Update target network counter every episode\n",
    "        if terminal_state:\n",
    "            self.target_update_counter += 1\n",
    "\n",
    "        # If counter reaches set value, update target network with weights of main network\n",
    "        if self.target_update_counter > UPDATE_TARGET_EVERY:\n",
    "            self.target_model.set_weights(self.model.get_weights())\n",
    "            self.target_update_counter = 0\n",
    "\n",
    "    # Queries main network for Q values given current observation space (environment state)\n",
    "    def get_qs(self, state):\n",
    "        return self.model.predict(np.expand_dims(np.array(state), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "incredible-submission",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                   | 0/1000 [00:00<?, ?episodes/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAME_STRING_PENALTY @ 1:  ( ' order by 3 / *\n",
      "MUTATION_PENALTY @ 1:  ( ' order by 3 / *\n",
      "PARSER_PENALTY @ 2:  1=1 ' order by 3 / *\n",
      "MUTATION_PENALTY @ 2:  1=1 ' order by 3 / *\n",
      "PARSER_PENALTY @ 3:  1=1 ' order by 3 / * *\n",
      "MUTATION_PENALTY @ 3:  1=1 ' order by 3 / * *\n",
      "PARSER_PENALTY @ 4:  1=1 ' order by 2 / * *\n",
      "MUTATION_PENALTY @ 4:  1=1 ' order by 2 / * *\n",
      "SAME_STRING_PENALTY @ 5:  1=1 ' order by 2 / * *\n",
      "MUTATION_PENALTY @ 5:  1=1 ' order by 2 / * *\n",
      "PARSER_PENALTY @ 6:  1=1 ' 1'/ by 2 / * *\n",
      "MUTATION_PENALTY @ 6:  1=1 ' 1'/ by 2 / * *\n",
      "PARSER_PENALTY @ 7:  1=1 ' 1'/ by 2 / * users/\n",
      "MUTATION_PENALTY @ 7:  1=1 ' 1'/ by 2 / * users/\n",
      "SAME_STRING_PENALTY @ 8:  1=1 ' 1'/ by 2 / * users/\n",
      "MUTATION_PENALTY @ 8:  1=1 ' 1'/ by 2 / * users/\n",
      "MUTATION_PENALTY @ 9:  1=1 -- 1'/ by 2 / * users/\n",
      "MUTATION_PENALTY @ 10:  1=1 -- 1'/ email 2 / * users/\n",
      "MUTATION_PENALTY @ 11:  1=1 -- 1'/ email 2 / * users/ 8\n",
      "MUTATION_PENALTY @ 12:  1=1 -- 1'/ email 2 / 3/ users/ 8\n",
      "MUTATION_PENALTY @ 13:  1=1 -- 1'/ 5 2 / 3/ users/ 8\n",
      "SAME_STRING_PENALTY @ 14:  1=1 -- 1'/ 5 2 / 3/ users/ 8\n",
      "MUTATION_PENALTY @ 14:  1=1 -- 1'/ 5 2 / 3/ users/ 8\n",
      "MUTATION_PENALTY @ 15:  1=1 -- 1'/ all_tables 2 / 3/ users/ 8\n",
      "PARSER_PENALTY @ 16:  5/ -- 1'/ all_tables 2 / 3/ users/ 8\n",
      "MUTATION_PENALTY @ 16:  5/ -- 1'/ all_tables 2 / 3/ users/ 8\n",
      "PARSER_PENALTY @ 17:  5/ -- 1'/ all_tables 2 / 3/ , 8\n",
      "MUTATION_PENALTY @ 17:  5/ -- 1'/ all_tables 2 / 3/ , 8\n",
      "PARSER_PENALTY @ 18:  5/ -- 1'/ all_tables 2 / 3/ , 4\n",
      "MUTATION_PENALTY @ 18:  5/ -- 1'/ all_tables 2 / 3/ , 4\n",
      "PARSER_PENALTY @ 19:  5/ -- 1'/ all_tables 2 / 3/ 4/ 4\n",
      "MUTATION_PENALTY @ 19:  5/ -- 1'/ all_tables 2 / 3/ 4/ 4\n",
      "PARSER_PENALTY @ 20:  5/ -- 1'/ all_tables 2 password 3/ 4/ 4\n",
      "MUTATION_PENALTY @ 20:  5/ -- 1'/ all_tables 2 password 3/ 4/ 4\n",
      "PARSER_PENALTY @ 21:  5/ -- 1'/ all_tables 2 password 3/ 4/ 9\n",
      "MUTATION_PENALTY @ 21:  5/ -- 1'/ all_tables 2 password 3/ 4/ 9\n",
      "PARSER_PENALTY @ 22:  5/ -- 1'/ all_tables 2 password 3/ 1/ 9\n",
      "MUTATION_PENALTY @ 22:  5/ -- 1'/ all_tables 2 password 3/ 1/ 9\n",
      "PARSER_PENALTY @ 23:  5/ -- 1'/ all_tables 2 password 3/ 1/ 9 users\n",
      "MUTATION_PENALTY @ 23:  5/ -- 1'/ all_tables 2 password 3/ 1/ 9 users\n",
      "PARSER_PENALTY @ 24:  5/ -- 1'/ all_tables 2 password 3/ 1/ 4/ users\n",
      "MUTATION_PENALTY @ 24:  5/ -- 1'/ all_tables 2 password 3/ 1/ 4/ users\n",
      "PARSER_PENALTY @ 25:  5/ ' 1'/ all_tables 2 password 3/ 1/ 4/ users\n",
      "MUTATION_PENALTY @ 25:  5/ ' 1'/ all_tables 2 password 3/ 1/ 4/ users\n",
      "PARSER_PENALTY @ 26:  5/ ' 1'/ all_tables 2 password instance/ 1/ 4/ users\n",
      "MUTATION_PENALTY @ 26:  5/ ' 1'/ all_tables 2 password instance/ 1/ 4/ users\n",
      "PARSER_PENALTY @ 27:  5/ ' 3/ all_tables 2 password instance/ 1/ 4/ users\n",
      "MUTATION_PENALTY @ 27:  5/ ' 3/ all_tables 2 password instance/ 1/ 4/ users\n",
      "PARSER_PENALTY @ 28:  5/ ' 3/ all_tables 2 password instance/ 1/ banner users\n",
      "MUTATION_PENALTY @ 28:  5/ ' 3/ all_tables 2 password instance/ 1/ banner users\n",
      "PARSER_PENALTY @ 29:  5/ ' 3/ all_tables , password instance/ 1/ banner users\n",
      "MUTATION_PENALTY @ 29:  5/ ' 3/ all_tables , password instance/ 1/ banner users\n",
      "PARSER_PENALTY @ 30:  5/ ' 3/ all_tables , password instance/ 1/ banner 1'/\n",
      "MUTATION_PENALTY @ 30:  5/ ' 3/ all_tables , password instance/ 1/ banner 1'/\n",
      "PARSER_PENALTY @ 31:  5/ , 3/ all_tables , password instance/ 1/ banner 1'/\n",
      "MUTATION_PENALTY @ 31:  5/ , 3/ all_tables , password instance/ 1/ banner 1'/\n",
      "SAME_STRING_PENALTY @ 32:  5/ , 3/ all_tables , password instance/ 1/ banner 1'/\n",
      "MUTATION_PENALTY @ 32:  5/ , 3/ all_tables , password instance/ 1/ banner 1'/\n",
      "PARSER_PENALTY @ 33:  5/ user 3/ all_tables , password instance/ 1/ banner 1'/\n",
      "MUTATION_PENALTY @ 33:  5/ user 3/ all_tables , password instance/ 1/ banner 1'/\n",
      "PARSER_PENALTY @ 34:  5/ user $ all_tables , password instance/ 1/ banner 1'/\n",
      "MUTATION_PENALTY @ 34:  5/ user $ all_tables , password instance/ 1/ banner 1'/\n",
      "PARSER_PENALTY @ 35:  5/ user $ all_tables , password instance/ 0 banner 1'/\n",
      "MUTATION_PENALTY @ 35:  5/ user $ all_tables , password instance/ 0 banner 1'/\n",
      "PARSER_PENALTY @ 36:  5/ user $ all_tables , password instance/ 0 banner version/\n",
      "MUTATION_PENALTY @ 36:  5/ user $ all_tables , password instance/ 0 banner version/\n",
      "PARSER_PENALTY @ 37:  or user $ all_tables , password instance/ 0 banner version/\n",
      "MUTATION_PENALTY @ 37:  or user $ all_tables , password instance/ 0 banner version/\n",
      "PARSER_PENALTY @ 38:  or all_tables/ $ all_tables , password instance/ 0 banner version/\n",
      "MUTATION_PENALTY @ 38:  or all_tables/ $ all_tables , password instance/ 0 banner version/\n",
      "PARSER_PENALTY @ 39:  4 all_tables/ $ all_tables , password instance/ 0 banner version/\n",
      "MUTATION_PENALTY @ 39:  4 all_tables/ $ all_tables , password instance/ 0 banner version/\n",
      "PARSER_PENALTY @ 40:  4 null $ all_tables , password instance/ 0 banner version/\n",
      "MUTATION_PENALTY @ 40:  4 null $ all_tables , password instance/ 0 banner version/\n",
      "PARSER_PENALTY @ 41:  order null $ all_tables , password instance/ 0 banner version/\n",
      "MUTATION_PENALTY @ 41:  order null $ all_tables , password instance/ 0 banner version/\n",
      "PARSER_PENALTY @ 42:  order null $ all_tables , password instance/ 0 banner 3/\n",
      "MUTATION_PENALTY @ 42:  order null $ all_tables , password instance/ 0 banner 3/\n",
      "PARSER_PENALTY @ 43:  order null $ all_tables , password instance/ 0 banner 5/\n",
      "MUTATION_PENALTY @ 43:  order null $ all_tables , password instance/ 0 banner 5/\n",
      "PARSER_PENALTY @ 44:  order null $ all_tables banner password instance/ 0 banner 5/\n",
      "MUTATION_PENALTY @ 44:  order null $ all_tables banner password instance/ 0 banner 5/\n",
      "PARSER_PENALTY @ 45:  order null $ all_tables banner password instance/ 0 union 5/\n",
      "MUTATION_PENALTY @ 45:  order null $ all_tables banner password instance/ 0 union 5/\n",
      "PARSER_PENALTY @ 46:  order null $ all_tables banner password instance/ 0 union version/\n",
      "MUTATION_PENALTY @ 46:  order null $ all_tables banner password instance/ 0 union version/\n",
      "PARSER_PENALTY @ 47:  order null $ all_tables banner [ instance/ 0 union version/\n",
      "MUTATION_PENALTY @ 47:  order null $ all_tables banner [ instance/ 0 union version/\n",
      "PARSER_PENALTY @ 48:  order null $ all_tables banner administrator'/ instance/ 0 union version/\n",
      "MUTATION_PENALTY @ 48:  order null $ all_tables banner administrator'/ instance/ 0 union version/\n",
      "PARSER_PENALTY @ 49:  order email $ all_tables banner administrator'/ instance/ 0 union version/\n",
      "MUTATION_PENALTY @ 49:  order email $ all_tables banner administrator'/ instance/ 0 union version/\n",
      "PARSER_PENALTY @ 50:  order email $ all_tables banner administrator'/ instance/ 1=1 union version/\n",
      "MUTATION_PENALTY @ 50:  order email $ all_tables banner administrator'/ instance/ 1=1 union version/\n",
      "PARSER_PENALTY @ 51:  order email $ version/ banner administrator'/ instance/ 1=1 union version/\n",
      "MUTATION_PENALTY @ 51:  order email $ version/ banner administrator'/ instance/ 1=1 union version/\n",
      "PARSER_PENALTY @ 52:  7/ email $ version/ banner administrator'/ instance/ 1=1 union version/\n",
      "MUTATION_PENALTY @ 52:  7/ email $ version/ banner administrator'/ instance/ 1=1 union version/\n",
      "PARSER_PENALTY @ 53:  7/ email $ null banner administrator'/ instance/ 1=1 union version/\n",
      "MUTATION_PENALTY @ 53:  7/ email $ null banner administrator'/ instance/ 1=1 union version/\n",
      "PARSER_PENALTY @ 54:  7/ email from null banner administrator'/ instance/ 1=1 union version/\n",
      "MUTATION_PENALTY @ 54:  7/ email from null banner administrator'/ instance/ 1=1 union version/\n",
      "PARSER_PENALTY @ 55:  7/ email from null banner administrator'/ instance/ 8/ union version/\n",
      "MUTATION_PENALTY @ 55:  7/ email from null banner administrator'/ instance/ 8/ union version/\n",
      "SAME_STRING_PENALTY @ 56:  7/ email from null banner administrator'/ instance/ 8/ union version/\n",
      "MUTATION_PENALTY @ 56:  7/ email from null banner administrator'/ instance/ 8/ union version/\n",
      "PARSER_PENALTY @ 57:  -- email from null banner administrator'/ instance/ 8/ union version/\n",
      "MUTATION_PENALTY @ 57:  -- email from null banner administrator'/ instance/ 8/ union version/\n",
      "PARSER_PENALTY @ 58:  -- email all_tables null banner administrator'/ instance/ 8/ union version/\n",
      "MUTATION_PENALTY @ 58:  -- email all_tables null banner administrator'/ instance/ 8/ union version/\n",
      "PARSER_PENALTY @ 59:  -- email all_tables 5 banner administrator'/ instance/ 8/ union version/\n",
      "MUTATION_PENALTY @ 59:  -- email all_tables 5 banner administrator'/ instance/ 8/ union version/\n",
      "PARSER_PENALTY @ 60:  -- email all_tables 5 by administrator'/ instance/ 8/ union version/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUTATION_PENALTY @ 60:  -- email all_tables 5 by administrator'/ instance/ 8/ union version/\n",
      "PARSER_PENALTY @ 61:  -- email all_tables 2/ by administrator'/ instance/ 8/ union version/\n",
      "MUTATION_PENALTY @ 61:  -- email all_tables 2/ by administrator'/ instance/ 8/ union version/\n",
      "PARSER_PENALTY @ 62:  -- email all_tables 2/ by administrator'/ , 8/ union version/\n",
      "MUTATION_PENALTY @ 62:  -- email all_tables 2/ by administrator'/ , 8/ union version/\n",
      "PARSER_PENALTY @ 63:  -- email all_tables ; by administrator'/ , 8/ union version/\n",
      "MUTATION_PENALTY @ 63:  -- email all_tables ; by administrator'/ , 8/ union version/\n",
      "PARSER_PENALTY @ 64:  2/ email all_tables ; by administrator'/ , 8/ union version/\n",
      "MUTATION_PENALTY @ 64:  2/ email all_tables ; by administrator'/ , 8/ union version/\n",
      "PARSER_PENALTY @ 65:  2/ email all_tables admin'/ by administrator'/ , 8/ union version/\n",
      "MUTATION_PENALTY @ 65:  2/ email all_tables admin'/ by administrator'/ , 8/ union version/\n",
      "PARSER_PENALTY @ 66:  2/ email all_tables admin'/ by users/ , 8/ union version/\n",
      "MUTATION_PENALTY @ 66:  2/ email all_tables admin'/ by users/ , 8/ union version/\n",
      "PARSER_PENALTY @ 67:  all_tables/ email all_tables admin'/ by users/ , 8/ union version/\n",
      "MUTATION_PENALTY @ 67:  all_tables/ email all_tables admin'/ by users/ , 8/ union version/\n",
      "PARSER_PENALTY @ 68:  all_tables/ email all_tables admin'/ by users/ , 8/ 8 version/\n",
      "MUTATION_PENALTY @ 68:  all_tables/ email all_tables admin'/ by users/ , 8/ 8 version/\n",
      "PARSER_PENALTY @ 69:  user email all_tables admin'/ by users/ , 8/ 8 version/\n",
      "MUTATION_PENALTY @ 69:  user email all_tables admin'/ by users/ , 8/ 8 version/\n",
      "PARSER_PENALTY @ 70:  user administrator all_tables admin'/ by users/ , 8/ 8 version/\n",
      "MUTATION_PENALTY @ 70:  user administrator all_tables admin'/ by users/ , 8/ 8 version/\n",
      "PARSER_PENALTY @ 71:  user administrator all_tables admin'/ by users/ admin'/ 8/ 8 version/\n",
      "MUTATION_PENALTY @ 71:  user administrator all_tables admin'/ by users/ admin'/ 8/ 8 version/\n",
      "PARSER_PENALTY @ 72:  user administrator all_tables admin'/ by users/ 5/ 8/ 8 version/\n",
      "MUTATION_PENALTY @ 72:  user administrator all_tables admin'/ by users/ 5/ 8/ 8 version/\n",
      "PARSER_PENALTY @ 73:  information_schema.tables/ administrator all_tables admin'/ by users/ 5/ 8/ 8 version/\n",
      "MUTATION_PENALTY @ 73:  information_schema.tables/ administrator all_tables admin'/ by users/ 5/ 8/ 8 version/\n",
      "PARSER_PENALTY @ 74:  information_schema.tables/ administrator all_tables admin'/ by users/ 5/ 8/ 8 or\n",
      "MUTATION_PENALTY @ 74:  information_schema.tables/ administrator all_tables admin'/ by users/ 5/ 8/ 8 or\n",
      "PARSER_PENALTY @ 75:  information_schema.tables/ administrator all_tables admin'/ by users/ 5/ 1=1 8 or\n",
      "MUTATION_PENALTY @ 75:  information_schema.tables/ administrator all_tables admin'/ by users/ 5/ 1=1 8 or\n",
      "PARSER_PENALTY @ 76:  instance administrator all_tables admin'/ by users/ 5/ 1=1 8 or\n",
      "MUTATION_PENALTY @ 76:  instance administrator all_tables admin'/ by users/ 5/ 1=1 8 or\n",
      "PARSER_PENALTY @ 77:  instance administrator all_tables admin'/ 4/ users/ 5/ 1=1 8 or\n",
      "MUTATION_PENALTY @ 77:  instance administrator all_tables admin'/ 4/ users/ 5/ 1=1 8 or\n",
      "PARSER_PENALTY @ 78:  instance administrator all_tables admin'/ 4/ dual/ 5/ 1=1 8 or\n",
      "MUTATION_PENALTY @ 78:  instance administrator all_tables admin'/ 4/ dual/ 5/ 1=1 8 or\n",
      "PARSER_PENALTY @ 79:  instance administrator all_tables admin'/ 4/ dual/ 5/ 1=1 dual/ or\n",
      "MUTATION_PENALTY @ 79:  instance administrator all_tables admin'/ 4/ dual/ 5/ 1=1 dual/ or\n",
      "PARSER_PENALTY @ 80:  instance administrator all_tables admin'/ 4/ dual/ 5/ 1'= dual/ or\n",
      "MUTATION_PENALTY @ 80:  instance administrator all_tables admin'/ 4/ dual/ 5/ 1'= dual/ or\n",
      "PARSER_PENALTY @ 81:  instance administrator all_tables admin'/ 4/ dual/ 5/ 1'= dual/ null\n",
      "MUTATION_PENALTY @ 81:  instance administrator all_tables admin'/ 4/ dual/ 5/ 1'= dual/ null\n",
      "SAME_STRING_PENALTY @ 82:  instance administrator all_tables admin'/ 4/ dual/ 5/ 1'= dual/ null\n",
      "MUTATION_PENALTY @ 82:  instance administrator all_tables admin'/ 4/ dual/ 5/ 1'= dual/ null\n",
      "PARSER_PENALTY @ 83:  instance administrator all_tables admin'/ 4/ dual/ or 1'= dual/ null\n",
      "MUTATION_PENALTY @ 83:  instance administrator all_tables admin'/ 4/ dual/ or 1'= dual/ null\n",
      "PARSER_PENALTY @ 84:  instance administrator all_tables admin'/ 4/ dual/ or 1'= union null\n",
      "MUTATION_PENALTY @ 84:  instance administrator all_tables admin'/ 4/ dual/ or 1'= union null\n",
      "PARSER_PENALTY @ 85:  instance administrator all_tables admin'/ 4/ dual/ or administrator union null\n",
      "MUTATION_PENALTY @ 85:  instance administrator all_tables admin'/ 4/ dual/ or administrator union null\n",
      "PARSER_PENALTY @ 86:  instance administrator admin'/ admin'/ 4/ dual/ or administrator union null\n",
      "MUTATION_PENALTY @ 86:  instance administrator admin'/ admin'/ 4/ dual/ or administrator union null\n",
      "PARSER_PENALTY @ 87:  instance administrator admin'/ admin'/ 4/ 9/ or administrator union null\n",
      "MUTATION_PENALTY @ 87:  instance administrator admin'/ admin'/ 4/ 9/ or administrator union null\n",
      "PARSER_PENALTY @ 88:  instance administrator admin'/ admin'/ 4/ 9/ or administrator instance/ null\n",
      "MUTATION_PENALTY @ 88:  instance administrator admin'/ admin'/ 4/ 9/ or administrator instance/ null\n",
      "PARSER_PENALTY @ 89:  instance 6 admin'/ admin'/ 4/ 9/ or administrator instance/ null\n",
      "MUTATION_PENALTY @ 89:  instance 6 admin'/ admin'/ 4/ 9/ or administrator instance/ null\n",
      "PARSER_PENALTY @ 90:  instance 6 admin'/ admin'/ 4/ 9/ or v instance/ null\n",
      "MUTATION_PENALTY @ 90:  instance 6 admin'/ admin'/ 4/ 9/ or v instance/ null\n",
      "PARSER_PENALTY @ 91:  instance 6 admin'/ admin'/ ' 9/ or v instance/ null\n",
      "MUTATION_PENALTY @ 91:  instance 6 admin'/ admin'/ ' 9/ or v instance/ null\n",
      "PARSER_PENALTY @ 92:  instance 6 admin'/ admin'/ ' 9/ or from instance/ null\n",
      "MUTATION_PENALTY @ 92:  instance 6 admin'/ admin'/ ' 9/ or from instance/ null\n",
      "PARSER_PENALTY @ 93:  instance 6 admin'/ admin'/ 4/ 9/ or from instance/ null\n",
      "MUTATION_PENALTY @ 93:  instance 6 admin'/ admin'/ 4/ 9/ or from instance/ null\n",
      "SAME_STRING_PENALTY @ 94:  instance 6 admin'/ admin'/ 4/ 9/ or from instance/ null\n",
      "MUTATION_PENALTY @ 94:  instance 6 admin'/ admin'/ 4/ 9/ or from instance/ null\n",
      "PARSER_PENALTY @ 95:  instance 6 admin'/ admin'/ 4/ 9/ or from instance/ 0/\n",
      "MUTATION_PENALTY @ 95:  instance 6 admin'/ admin'/ 4/ 9/ or from instance/ 0/\n",
      "PARSER_PENALTY @ 96:  1=1 6 admin'/ admin'/ 4/ 9/ or from instance/ 0/\n",
      "MUTATION_PENALTY @ 96:  1=1 6 admin'/ admin'/ 4/ 9/ or from instance/ 0/\n",
      "SAME_STRING_PENALTY @ 97:  1=1 6 admin'/ admin'/ 4/ 9/ or from instance/ 0/\n",
      "MUTATION_PENALTY @ 97:  1=1 6 admin'/ admin'/ 4/ 9/ or from instance/ 0/\n",
      "PARSER_PENALTY @ 98:  1=1 $ admin'/ admin'/ 4/ 9/ or from instance/ 0/\n",
      "MUTATION_PENALTY @ 98:  1=1 $ admin'/ admin'/ 4/ 9/ or from instance/ 0/\n",
      "PARSER_PENALTY @ 99:  1=1 $ admin'/ admin'/ dual/ 9/ or from instance/ 0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                         | 1/1000 [00:16<4:32:06, 16.34s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUTATION_PENALTY @ 99:  1=1 $ admin'/ admin'/ dual/ 9/ or from instance/ 0/\n",
      "PARSER_PENALTY @ 100:  1=1 $ admin'/ admin'/ dual/ 9/ or from 7 0/\n",
      "MUTATION_PENALTY @ 100:  1=1 $ admin'/ admin'/ dual/ 9/ or from 7 0/\n",
      "MUTATION_PENALTY @ 1:  [ ' ) union select null from user -- [\n",
      "PARSER_PENALTY @ 2:  [ ' admin'/ union select null from user -- [\n",
      "MUTATION_PENALTY @ 2:  [ ' admin'/ union select null from user -- [\n",
      "PARSER_PENALTY @ 3:  [ ' admin'/ union select null from user $ [\n",
      "MUTATION_PENALTY @ 3:  [ ' admin'/ union select null from user $ [\n",
      "SAME_STRING_PENALTY @ 4:  [ ' admin'/ union select null from user $ [\n",
      "MUTATION_PENALTY @ 4:  [ ' admin'/ union select null from user $ [\n",
      "PARSER_PENALTY @ 5:  [ ' admin'/ union select select from user $ [\n",
      "MUTATION_PENALTY @ 5:  [ ' admin'/ union select select from user $ [\n",
      "PARSER_PENALTY @ 6:  [ ' admin'/ union select 0/ from user $ [\n",
      "MUTATION_PENALTY @ 6:  [ ' admin'/ union select 0/ from user $ [\n",
      "PARSER_PENALTY @ 7:  1'= ' admin'/ union select 0/ from user $ [\n",
      "MUTATION_PENALTY @ 7:  1'= ' admin'/ union select 0/ from user $ [\n",
      "PARSER_PENALTY @ 8:  1'= ' admin'/ users/ select 0/ from user $ [\n",
      "MUTATION_PENALTY @ 8:  1'= ' admin'/ users/ select 0/ from user $ [\n",
      "PARSER_PENALTY @ 9:  1'=\n",
      "MUTATION_PENALTY @ 9:  1'=\n",
      "SAME_STRING_PENALTY @ 10:  1'=\n",
      "MUTATION_PENALTY @ 10:  1'=\n",
      "SAME_STRING_PENALTY @ 11:  1'=\n",
      "MUTATION_PENALTY @ 11:  1'=\n",
      "SAME_STRING_PENALTY @ 12:  1'=\n",
      "MUTATION_PENALTY @ 12:  1'=\n",
      "SAME_STRING_PENALTY @ 13:  1'=\n",
      "MUTATION_PENALTY @ 13:  1'=\n",
      "SAME_STRING_PENALTY @ 14:  1'=\n",
      "MUTATION_PENALTY @ 14:  1'=\n",
      "SAME_STRING_PENALTY @ 15:  1'=\n",
      "MUTATION_PENALTY @ 15:  1'=\n",
      "SAME_STRING_PENALTY @ 16:  1'=\n",
      "MUTATION_PENALTY @ 16:  1'=\n",
      "SAME_STRING_PENALTY @ 17:  1'=\n",
      "MUTATION_PENALTY @ 17:  1'=\n",
      "MUTATION_PENALTY @ 18:  1'= 0\n",
      "SAME_STRING_PENALTY @ 19:  1'= 0\n",
      "MUTATION_PENALTY @ 19:  1'= 0\n",
      "SAME_STRING_PENALTY @ 20:  1'= 0\n",
      "MUTATION_PENALTY @ 20:  1'= 0\n",
      "SAME_STRING_PENALTY @ 21:  1'= 0\n",
      "MUTATION_PENALTY @ 21:  1'= 0\n",
      "SAME_STRING_PENALTY @ 22:  1'= 0\n",
      "MUTATION_PENALTY @ 22:  1'= 0\n",
      "PARSER_PENALTY @ 23:  ( 0\n",
      "MUTATION_PENALTY @ 23:  ( 0\n",
      "MUTATION_PENALTY @ 24:  ( 0 '\n",
      "PARSER_PENALTY @ 25:  ( 0 user/\n",
      "MUTATION_PENALTY @ 25:  ( 0 user/\n",
      "SAME_STRING_PENALTY @ 26:  ( 0 user/\n",
      "MUTATION_PENALTY @ 26:  ( 0 user/\n",
      "SAME_STRING_PENALTY @ 27:  ( 0 user/\n",
      "MUTATION_PENALTY @ 27:  ( 0 user/\n",
      "PARSER_PENALTY @ 28:  ( 0 user/ by\n",
      "MUTATION_PENALTY @ 28:  ( 0 user/ by\n",
      "SAME_STRING_PENALTY @ 29:  ( 0 user/ by\n",
      "MUTATION_PENALTY @ 29:  ( 0 user/ by\n",
      "PARSER_PENALTY @ 30:  ( 0 user/ by administrator\n",
      "MUTATION_PENALTY @ 30:  ( 0 user/ by administrator\n",
      "MUTATION_PENALTY @ 31:  ( 0 ; by administrator\n",
      "PARSER_PENALTY @ 32:  ( 0 admin'/ by administrator\n",
      "MUTATION_PENALTY @ 32:  ( 0 admin'/ by administrator\n",
      "SAME_STRING_PENALTY @ 33:  ( 0 admin'/ by administrator\n",
      "MUTATION_PENALTY @ 33:  ( 0 admin'/ by administrator\n",
      "PARSER_PENALTY @ 34:  ( 0 admin'/ by administrator --\n",
      "MUTATION_PENALTY @ 34:  ( 0 admin'/ by administrator --\n",
      "PARSER_PENALTY @ 35:  ( 0 admin'/ by administrator ,\n",
      "MUTATION_PENALTY @ 35:  ( 0 admin'/ by administrator ,\n",
      "SAME_STRING_PENALTY @ 36:  ( 0 admin'/ by administrator ,\n",
      "MUTATION_PENALTY @ 36:  ( 0 admin'/ by administrator ,\n",
      "SAME_STRING_PENALTY @ 37:  ( 0 admin'/ by administrator ,\n",
      "MUTATION_PENALTY @ 37:  ( 0 admin'/ by administrator ,\n",
      "PARSER_PENALTY @ 38:  ( users/ admin'/ by administrator ,\n",
      "MUTATION_PENALTY @ 38:  ( users/ admin'/ by administrator ,\n",
      "PARSER_PENALTY @ 39:  ( users/ admin'/ by administrator v\n",
      "MUTATION_PENALTY @ 39:  ( users/ admin'/ by administrator v\n",
      "PARSER_PENALTY @ 40:  ( users/ instance/ by administrator v\n",
      "MUTATION_PENALTY @ 40:  ( users/ instance/ by administrator v\n",
      "PARSER_PENALTY @ 41:  ( users/ [ by administrator v\n",
      "MUTATION_PENALTY @ 41:  ( users/ [ by administrator v\n",
      "SAME_STRING_PENALTY @ 42:  ( users/ [ by administrator v\n",
      "MUTATION_PENALTY @ 42:  ( users/ [ by administrator v\n",
      "SAME_STRING_PENALTY @ 43:  ( users/ [ by administrator v\n",
      "MUTATION_PENALTY @ 43:  ( users/ [ by administrator v\n",
      "PARSER_PENALTY @ 44:  ( , [ by administrator v\n",
      "MUTATION_PENALTY @ 44:  ( , [ by administrator v\n",
      "SAME_STRING_PENALTY @ 45:  ( , [ by administrator v\n",
      "MUTATION_PENALTY @ 45:  ( , [ by administrator v\n",
      "PARSER_PENALTY @ 46:  ( , [ by administrator v instance\n",
      "MUTATION_PENALTY @ 46:  ( , [ by administrator v instance\n",
      "PARSER_PENALTY @ 47:  ( , [ by administrator v )\n",
      "MUTATION_PENALTY @ 47:  ( , [ by administrator v )\n",
      "SAME_STRING_PENALTY @ 48:  ( , [ by administrator v )\n",
      "MUTATION_PENALTY @ 48:  ( , [ by administrator v )\n",
      "PARSER_PENALTY @ 49:  ( , [ by administrator v 2\n",
      "MUTATION_PENALTY @ 49:  ( , [ by administrator v 2\n",
      "PARSER_PENALTY @ 50:  ( , instance/ by administrator v 2\n",
      "MUTATION_PENALTY @ 50:  ( , instance/ by administrator v 2\n",
      "Train on 128 samples\n",
      "128/128 - 3s - loss: 0.1045 - q_pos_loss: 0.0897 - q_vocab_loss: 0.0148 - q_pos_accuracy: 0.6562 - q_vocab_accuracy: 0.5234\n",
      "PARSER_PENALTY @ 51:  ( dual instance/ by administrator v 2\n",
      "MUTATION_PENALTY @ 51:  ( dual instance/ by administrator v 2\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.1033 - q_pos_loss: 0.0886 - q_vocab_loss: 0.0147 - q_pos_accuracy: 0.8281 - q_vocab_accuracy: 0.6953\n",
      "PARSER_PENALTY @ 52:  ( dual instance/ by administrator v 1/\n",
      "MUTATION_PENALTY @ 52:  ( dual instance/ by administrator v 1/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.1027 - q_pos_loss: 0.0880 - q_vocab_loss: 0.0147 - q_pos_accuracy: 0.7734 - q_vocab_accuracy: 0.6797\n",
      "PARSER_PENALTY @ 53:  ( dual instance/ 6/ administrator v 1/\n",
      "MUTATION_PENALTY @ 53:  ( dual instance/ 6/ administrator v 1/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.1020 - q_pos_loss: 0.0873 - q_vocab_loss: 0.0146 - q_pos_accuracy: 0.6953 - q_vocab_accuracy: 0.6328\n",
      "PARSER_PENALTY @ 54:  ( dual instance/ 0/ administrator v 1/\n",
      "MUTATION_PENALTY @ 54:  ( dual instance/ 0/ administrator v 1/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.1011 - q_pos_loss: 0.0865 - q_vocab_loss: 0.0146 - q_pos_accuracy: 0.7188 - q_vocab_accuracy: 0.6016\n",
      "PARSER_PENALTY @ 55:  ( dual instance/ dual administrator v 1/\n",
      "MUTATION_PENALTY @ 55:  ( dual instance/ dual administrator v 1/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.1002 - q_pos_loss: 0.0857 - q_vocab_loss: 0.0145 - q_pos_accuracy: 0.7188 - q_vocab_accuracy: 0.5625\n",
      "SAME_STRING_PENALTY @ 56:  ( dual instance/ dual administrator v 1/\n",
      "MUTATION_PENALTY @ 56:  ( dual instance/ dual administrator v 1/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0984 - q_pos_loss: 0.0839 - q_vocab_loss: 0.0145 - q_pos_accuracy: 0.7031 - q_vocab_accuracy: 0.5703\n",
      "PARSER_PENALTY @ 57:  ( dual administrator'/ dual administrator v 1/\n",
      "MUTATION_PENALTY @ 57:  ( dual administrator'/ dual administrator v 1/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0979 - q_pos_loss: 0.0835 - q_vocab_loss: 0.0144 - q_pos_accuracy: 0.6875 - q_vocab_accuracy: 0.6797\n",
      "MUTATION_PENALTY @ 58:  (\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0959 - q_pos_loss: 0.0815 - q_vocab_loss: 0.0144 - q_pos_accuracy: 0.7500 - q_vocab_accuracy: 0.6562\n",
      "SAME_STRING_PENALTY @ 59:  (\n",
      "MUTATION_PENALTY @ 59:  (\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0940 - q_pos_loss: 0.0797 - q_vocab_loss: 0.0143 - q_pos_accuracy: 0.7500 - q_vocab_accuracy: 0.6484\n",
      "MUTATION_PENALTY @ 60:  #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0911 - q_pos_loss: 0.0768 - q_vocab_loss: 0.0142 - q_pos_accuracy: 0.7812 - q_vocab_accuracy: 0.5625\n",
      "SAME_STRING_PENALTY @ 61:  #\n",
      "MUTATION_PENALTY @ 61:  #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0902 - q_pos_loss: 0.0761 - q_vocab_loss: 0.0141 - q_pos_accuracy: 0.7344 - q_vocab_accuracy: 0.5938\n",
      "SAME_STRING_PENALTY @ 62:  #\n",
      "MUTATION_PENALTY @ 62:  #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0884 - q_pos_loss: 0.0743 - q_vocab_loss: 0.0141 - q_pos_accuracy: 0.7422 - q_vocab_accuracy: 0.6797\n",
      "PARSER_PENALTY @ 63:  # 0/\n",
      "MUTATION_PENALTY @ 63:  # 0/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0867 - q_pos_loss: 0.0727 - q_vocab_loss: 0.0140 - q_pos_accuracy: 0.6406 - q_vocab_accuracy: 0.6562\n",
      "SAME_STRING_PENALTY @ 64:  # 0/\n",
      "MUTATION_PENALTY @ 64:  # 0/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0825 - q_pos_loss: 0.0687 - q_vocab_loss: 0.0139 - q_pos_accuracy: 0.6406 - q_vocab_accuracy: 0.6719\n",
      "SAME_STRING_PENALTY @ 65:  # 0/\n",
      "MUTATION_PENALTY @ 65:  # 0/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0829 - q_pos_loss: 0.0689 - q_vocab_loss: 0.0140 - q_pos_accuracy: 0.6172 - q_vocab_accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARSER_PENALTY @ 66:  # select\n",
      "MUTATION_PENALTY @ 66:  # select\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0797 - q_pos_loss: 0.0660 - q_vocab_loss: 0.0137 - q_pos_accuracy: 0.5156 - q_vocab_accuracy: 0.7266\n",
      "SAME_STRING_PENALTY @ 67:  # select\n",
      "MUTATION_PENALTY @ 67:  # select\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0751 - q_pos_loss: 0.0613 - q_vocab_loss: 0.0138 - q_pos_accuracy: 0.5156 - q_vocab_accuracy: 0.6797\n",
      "SAME_STRING_PENALTY @ 68:  # select\n",
      "MUTATION_PENALTY @ 68:  # select\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0796 - q_pos_loss: 0.0659 - q_vocab_loss: 0.0137 - q_pos_accuracy: 0.4453 - q_vocab_accuracy: 0.6016\n",
      "PARSER_PENALTY @ 69:  3/ select\n",
      "MUTATION_PENALTY @ 69:  3/ select\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0739 - q_pos_loss: 0.0602 - q_vocab_loss: 0.0137 - q_pos_accuracy: 0.4688 - q_vocab_accuracy: 0.6172\n",
      "SAME_STRING_PENALTY @ 70:  3/ select\n",
      "MUTATION_PENALTY @ 70:  3/ select\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0747 - q_pos_loss: 0.0613 - q_vocab_loss: 0.0135 - q_pos_accuracy: 0.4844 - q_vocab_accuracy: 0.6016\n",
      "PARSER_PENALTY @ 71:  3/ #\n",
      "MUTATION_PENALTY @ 71:  3/ #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0716 - q_pos_loss: 0.0581 - q_vocab_loss: 0.0135 - q_pos_accuracy: 0.5000 - q_vocab_accuracy: 0.5000\n",
      "SAME_STRING_PENALTY @ 72:  3/ #\n",
      "MUTATION_PENALTY @ 72:  3/ #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0736 - q_pos_loss: 0.0600 - q_vocab_loss: 0.0135 - q_pos_accuracy: 0.4141 - q_vocab_accuracy: 0.4219\n",
      "SAME_STRING_PENALTY @ 73:  3/ #\n",
      "MUTATION_PENALTY @ 73:  3/ #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0699 - q_pos_loss: 0.0564 - q_vocab_loss: 0.0135 - q_pos_accuracy: 0.3594 - q_vocab_accuracy: 0.4844\n",
      "SAME_STRING_PENALTY @ 74:  3/ #\n",
      "MUTATION_PENALTY @ 74:  3/ #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0696 - q_pos_loss: 0.0563 - q_vocab_loss: 0.0133 - q_pos_accuracy: 0.4453 - q_vocab_accuracy: 0.5703\n",
      "PARSER_PENALTY @ 75:  3/ # 8/\n",
      "MUTATION_PENALTY @ 75:  3/ # 8/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0654 - q_pos_loss: 0.0521 - q_vocab_loss: 0.0133 - q_pos_accuracy: 0.5078 - q_vocab_accuracy: 0.6719\n",
      "PARSER_PENALTY @ 76:  3/ # 8/ 9\n",
      "MUTATION_PENALTY @ 76:  3/ # 8/ 9\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0690 - q_pos_loss: 0.0557 - q_vocab_loss: 0.0134 - q_pos_accuracy: 0.5234 - q_vocab_accuracy: 0.6719\n",
      "MUTATION_PENALTY @ 77:  3/ ) 8/ 9\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0623 - q_pos_loss: 0.0493 - q_vocab_loss: 0.0130 - q_pos_accuracy: 0.5234 - q_vocab_accuracy: 0.7188\n",
      "SAME_STRING_PENALTY @ 78:  3/ ) 8/ 9\n",
      "MUTATION_PENALTY @ 78:  3/ ) 8/ 9\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0674 - q_pos_loss: 0.0545 - q_vocab_loss: 0.0129 - q_pos_accuracy: 0.5234 - q_vocab_accuracy: 0.6953\n",
      "PARSER_PENALTY @ 79:  all_tables ) 8/ 9\n",
      "MUTATION_PENALTY @ 79:  all_tables ) 8/ 9\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0656 - q_pos_loss: 0.0527 - q_vocab_loss: 0.0129 - q_pos_accuracy: 0.5938 - q_vocab_accuracy: 0.6719\n",
      "SAME_STRING_PENALTY @ 80:  all_tables ) 8/ 9\n",
      "MUTATION_PENALTY @ 80:  all_tables ) 8/ 9\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0650 - q_pos_loss: 0.0522 - q_vocab_loss: 0.0128 - q_pos_accuracy: 0.6094 - q_vocab_accuracy: 0.5938\n",
      "PARSER_PENALTY @ 81:  all_tables ) 8/ 9 users\n",
      "MUTATION_PENALTY @ 81:  all_tables ) 8/ 9 users\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0627 - q_pos_loss: 0.0501 - q_vocab_loss: 0.0127 - q_pos_accuracy: 0.5391 - q_vocab_accuracy: 0.5781\n",
      "SAME_STRING_PENALTY @ 82:  all_tables ) 8/ 9 users\n",
      "MUTATION_PENALTY @ 82:  all_tables ) 8/ 9 users\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0571 - q_pos_loss: 0.0448 - q_vocab_loss: 0.0123 - q_pos_accuracy: 0.6797 - q_vocab_accuracy: 0.5625\n",
      "PARSER_PENALTY @ 83:  all_tables ) 8/ all_tables/ users\n",
      "MUTATION_PENALTY @ 83:  all_tables ) 8/ all_tables/ users\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0642 - q_pos_loss: 0.0517 - q_vocab_loss: 0.0125 - q_pos_accuracy: 0.6094 - q_vocab_accuracy: 0.6016\n",
      "MUTATION_PENALTY @ 84:  9/ ) 8/ all_tables/ users\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0590 - q_pos_loss: 0.0464 - q_vocab_loss: 0.0125 - q_pos_accuracy: 0.6016 - q_vocab_accuracy: 0.6016\n",
      "PARSER_PENALTY @ 85:  9/ instance 8/ all_tables/ users\n",
      "MUTATION_PENALTY @ 85:  9/ instance 8/ all_tables/ users\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0582 - q_pos_loss: 0.0461 - q_vocab_loss: 0.0120 - q_pos_accuracy: 0.5703 - q_vocab_accuracy: 0.5391\n",
      "PARSER_PENALTY @ 86:  9/ instance 8/ 7 users\n",
      "MUTATION_PENALTY @ 86:  9/ instance 8/ 7 users\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0580 - q_pos_loss: 0.0456 - q_vocab_loss: 0.0124 - q_pos_accuracy: 0.5859 - q_vocab_accuracy: 0.5391\n",
      "PARSER_PENALTY @ 87:  9/ instance user/ 7 users\n",
      "MUTATION_PENALTY @ 87:  9/ instance user/ 7 users\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0592 - q_pos_loss: 0.0472 - q_vocab_loss: 0.0120 - q_pos_accuracy: 0.5469 - q_vocab_accuracy: 0.4844\n",
      "SAME_STRING_PENALTY @ 88:  9/ instance user/ 7 users\n",
      "MUTATION_PENALTY @ 88:  9/ instance user/ 7 users\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0597 - q_pos_loss: 0.0475 - q_vocab_loss: 0.0122 - q_pos_accuracy: 0.4297 - q_vocab_accuracy: 0.5469\n",
      "PARSER_PENALTY @ 89:  information_schema.tables instance user/ 7 users\n",
      "MUTATION_PENALTY @ 89:  information_schema.tables instance user/ 7 users\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0571 - q_pos_loss: 0.0452 - q_vocab_loss: 0.0120 - q_pos_accuracy: 0.4766 - q_vocab_accuracy: 0.5547\n",
      "PARSER_PENALTY @ 90:  information_schema.tables instance user/ all_tables users\n",
      "MUTATION_PENALTY @ 90:  information_schema.tables instance user/ all_tables users\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0563 - q_pos_loss: 0.0443 - q_vocab_loss: 0.0121 - q_pos_accuracy: 0.4844 - q_vocab_accuracy: 0.4531\n",
      "SAME_STRING_PENALTY @ 91:  information_schema.tables instance user/ all_tables users\n",
      "MUTATION_PENALTY @ 91:  information_schema.tables instance user/ all_tables users\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0549 - q_pos_loss: 0.0432 - q_vocab_loss: 0.0117 - q_pos_accuracy: 0.5625 - q_vocab_accuracy: 0.5625\n",
      "PARSER_PENALTY @ 92:  information_schema.tables instance user/ all_tables /\n",
      "MUTATION_PENALTY @ 92:  information_schema.tables instance user/ all_tables /\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0531 - q_pos_loss: 0.0415 - q_vocab_loss: 0.0116 - q_pos_accuracy: 0.4922 - q_vocab_accuracy: 0.6250\n",
      "SAME_STRING_PENALTY @ 93:  information_schema.tables instance user/ all_tables /\n",
      "MUTATION_PENALTY @ 93:  information_schema.tables instance user/ all_tables /\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0476 - q_pos_loss: 0.0358 - q_vocab_loss: 0.0117 - q_pos_accuracy: 0.5547 - q_vocab_accuracy: 0.6328\n",
      "PARSER_PENALTY @ 94:  information_schema.tables instance user/ all_tables / 9/\n",
      "MUTATION_PENALTY @ 94:  information_schema.tables instance user/ all_tables / 9/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0500 - q_pos_loss: 0.0384 - q_vocab_loss: 0.0116 - q_pos_accuracy: 0.5391 - q_vocab_accuracy: 0.7500\n",
      "PARSER_PENALTY @ 95:  information_schema.tables instance user/ all_tables / banner\n",
      "MUTATION_PENALTY @ 95:  information_schema.tables instance user/ all_tables / banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0486 - q_pos_loss: 0.0372 - q_vocab_loss: 0.0114 - q_pos_accuracy: 0.5781 - q_vocab_accuracy: 0.6797\n",
      "SAME_STRING_PENALTY @ 96:  information_schema.tables instance user/ all_tables / banner\n",
      "MUTATION_PENALTY @ 96:  information_schema.tables instance user/ all_tables / banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0467 - q_pos_loss: 0.0352 - q_vocab_loss: 0.0115 - q_pos_accuracy: 0.5625 - q_vocab_accuracy: 0.7344\n",
      "SAME_STRING_PENALTY @ 97:  information_schema.tables instance user/ all_tables / banner\n",
      "MUTATION_PENALTY @ 97:  information_schema.tables instance user/ all_tables / banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0436 - q_pos_loss: 0.0322 - q_vocab_loss: 0.0114 - q_pos_accuracy: 0.5469 - q_vocab_accuracy: 0.6562\n",
      "SAME_STRING_PENALTY @ 98:  information_schema.tables instance user/ all_tables / banner\n",
      "MUTATION_PENALTY @ 98:  information_schema.tables instance user/ all_tables / banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0487 - q_pos_loss: 0.0375 - q_vocab_loss: 0.0111 - q_pos_accuracy: 0.5156 - q_vocab_accuracy: 0.7422\n",
      "SAME_STRING_PENALTY @ 99:  information_schema.tables instance user/ all_tables / banner\n",
      "MUTATION_PENALTY @ 99:  information_schema.tables instance user/ all_tables / banner\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0474 - q_pos_loss: 0.0358 - q_vocab_loss: 0.0115 - q_pos_accuracy: 0.5234 - q_vocab_accuracy: 0.7812\n",
      "PARSER_PENALTY @ 100:  information_schema.tables instance user/ union / banner\n",
      "MUTATION_PENALTY @ 100:  information_schema.tables instance user/ union / banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0469 - q_pos_loss: 0.0359 - q_vocab_loss: 0.0110 - q_pos_accuracy: 0.5938 - q_vocab_accuracy: 0.7578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|1                                                                        | 2/1000 [00:44<5:31:19, 19.92s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUTATION_PENALTY @ 1:  information_schema.tables order by 7 ; #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0449 - q_pos_loss: 0.0342 - q_vocab_loss: 0.0107 - q_pos_accuracy: 0.6094 - q_vocab_accuracy: 0.7656\n",
      "PARSER_PENALTY @ 2:  information_schema.tables administrator by 7 ; #\n",
      "MUTATION_PENALTY @ 2:  information_schema.tables administrator by 7 ; #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0438 - q_pos_loss: 0.0332 - q_vocab_loss: 0.0106 - q_pos_accuracy: 0.6406 - q_vocab_accuracy: 0.8125\n",
      "PARSER_PENALTY @ 3:  information_schema.tables , by 7 ; #\n",
      "MUTATION_PENALTY @ 3:  information_schema.tables , by 7 ; #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0461 - q_pos_loss: 0.0346 - q_vocab_loss: 0.0115 - q_pos_accuracy: 0.6406 - q_vocab_accuracy: 0.7188\n",
      "PARSER_PENALTY @ 4:  information_schema.tables , by 7 ; [\n",
      "MUTATION_PENALTY @ 4:  information_schema.tables , by 7 ; [\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0430 - q_pos_loss: 0.0327 - q_vocab_loss: 0.0103 - q_pos_accuracy: 0.6562 - q_vocab_accuracy: 0.8047\n",
      "PARSER_PENALTY @ 5:  information_schema.tables , by 7 ; 6\n",
      "MUTATION_PENALTY @ 5:  information_schema.tables , by 7 ; 6\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0437 - q_pos_loss: 0.0332 - q_vocab_loss: 0.0105 - q_pos_accuracy: 0.5312 - q_vocab_accuracy: 0.7344\n",
      "SAME_STRING_PENALTY @ 6:  information_schema.tables , by 7 ; 6\n",
      "MUTATION_PENALTY @ 6:  information_schema.tables , by 7 ; 6\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0410 - q_pos_loss: 0.0305 - q_vocab_loss: 0.0105 - q_pos_accuracy: 0.5703 - q_vocab_accuracy: 0.7500\n",
      "SAME_STRING_PENALTY @ 7:  information_schema.tables , by 7 ; 6\n",
      "MUTATION_PENALTY @ 7:  information_schema.tables , by 7 ; 6\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0451 - q_pos_loss: 0.0349 - q_vocab_loss: 0.0103 - q_pos_accuracy: 0.4844 - q_vocab_accuracy: 0.8125\n",
      "SAME_STRING_PENALTY @ 8:  information_schema.tables , by 7 ; 6\n",
      "MUTATION_PENALTY @ 8:  information_schema.tables , by 7 ; 6\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0374 - q_pos_loss: 0.0270 - q_vocab_loss: 0.0105 - q_pos_accuracy: 0.5781 - q_vocab_accuracy: 0.7344\n",
      "SAME_STRING_PENALTY @ 9:  information_schema.tables , by 7 ; 6\n",
      "MUTATION_PENALTY @ 9:  information_schema.tables , by 7 ; 6\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0434 - q_pos_loss: 0.0338 - q_vocab_loss: 0.0096 - q_pos_accuracy: 0.5547 - q_vocab_accuracy: 0.8125\n",
      "PARSER_PENALTY @ 10:  information_schema.tables , 9 7 ; 6\n",
      "MUTATION_PENALTY @ 10:  information_schema.tables , 9 7 ; 6\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0425 - q_pos_loss: 0.0323 - q_vocab_loss: 0.0103 - q_pos_accuracy: 0.4531 - q_vocab_accuracy: 0.7969\n",
      "PARSER_PENALTY @ 11:  information_schema.tables , 9 7 admin'/ 6\n",
      "MUTATION_PENALTY @ 11:  information_schema.tables , 9 7 admin'/ 6\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0402 - q_pos_loss: 0.0304 - q_vocab_loss: 0.0098 - q_pos_accuracy: 0.5547 - q_vocab_accuracy: 0.7812\n",
      "SAME_STRING_PENALTY @ 12:  information_schema.tables , 9 7 admin'/ 6\n",
      "MUTATION_PENALTY @ 12:  information_schema.tables , 9 7 admin'/ 6\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0385 - q_pos_loss: 0.0292 - q_vocab_loss: 0.0093 - q_pos_accuracy: 0.6250 - q_vocab_accuracy: 0.8438\n",
      "PARSER_PENALTY @ 13:  all_tables/ , 9 7 admin'/ 6\n",
      "MUTATION_PENALTY @ 13:  all_tables/ , 9 7 admin'/ 6\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0393 - q_pos_loss: 0.0300 - q_vocab_loss: 0.0093 - q_pos_accuracy: 0.5469 - q_vocab_accuracy: 0.8516\n",
      "PARSER_PENALTY @ 14:  all_tables/ # 9 7 admin'/ 6\n",
      "MUTATION_PENALTY @ 14:  all_tables/ # 9 7 admin'/ 6\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0372 - q_pos_loss: 0.0281 - q_vocab_loss: 0.0091 - q_pos_accuracy: 0.6094 - q_vocab_accuracy: 0.8672\n",
      "SAME_STRING_PENALTY @ 15:  all_tables/ # 9 7 admin'/ 6\n",
      "MUTATION_PENALTY @ 15:  all_tables/ # 9 7 admin'/ 6\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0380 - q_pos_loss: 0.0286 - q_vocab_loss: 0.0094 - q_pos_accuracy: 0.5469 - q_vocab_accuracy: 0.8438\n",
      "SAME_STRING_PENALTY @ 16:  all_tables/ # 9 7 admin'/ 6\n",
      "MUTATION_PENALTY @ 16:  all_tables/ # 9 7 admin'/ 6\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0409 - q_pos_loss: 0.0315 - q_vocab_loss: 0.0094 - q_pos_accuracy: 0.6250 - q_vocab_accuracy: 0.8359\n",
      "PARSER_PENALTY @ 17:  all_tables/ # 9 7 admin'/ [\n",
      "MUTATION_PENALTY @ 17:  all_tables/ # 9 7 admin'/ [\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0389 - q_pos_loss: 0.0300 - q_vocab_loss: 0.0088 - q_pos_accuracy: 0.6328 - q_vocab_accuracy: 0.8438\n",
      "PARSER_PENALTY @ 18:  all_tables/ # 9 # admin'/ [\n",
      "MUTATION_PENALTY @ 18:  all_tables/ # 9 # admin'/ [\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0379 - q_pos_loss: 0.0289 - q_vocab_loss: 0.0090 - q_pos_accuracy: 0.6016 - q_vocab_accuracy: 0.8359\n",
      "PARSER_PENALTY @ 19:  all_tables/ # 9 # admin'/ ,\n",
      "MUTATION_PENALTY @ 19:  all_tables/ # 9 # admin'/ ,\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0392 - q_pos_loss: 0.0299 - q_vocab_loss: 0.0093 - q_pos_accuracy: 0.5938 - q_vocab_accuracy: 0.8438\n",
      "SAME_STRING_PENALTY @ 20:  all_tables/ # 9 # admin'/ ,\n",
      "MUTATION_PENALTY @ 20:  all_tables/ # 9 # admin'/ ,\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0390 - q_pos_loss: 0.0299 - q_vocab_loss: 0.0091 - q_pos_accuracy: 0.5547 - q_vocab_accuracy: 0.8516\n",
      "PARSER_PENALTY @ 21:  all_tables/ # 9 # admin'/ #\n",
      "MUTATION_PENALTY @ 21:  all_tables/ # 9 # admin'/ #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0346 - q_pos_loss: 0.0254 - q_vocab_loss: 0.0092 - q_pos_accuracy: 0.5938 - q_vocab_accuracy: 0.7578\n",
      "PARSER_PENALTY @ 22:  all_tables/ # 9 8 admin'/ #\n",
      "MUTATION_PENALTY @ 22:  all_tables/ # 9 8 admin'/ #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0376 - q_pos_loss: 0.0285 - q_vocab_loss: 0.0091 - q_pos_accuracy: 0.5781 - q_vocab_accuracy: 0.8203\n",
      "PARSER_PENALTY @ 23:  all_tables/ 3/ 9 8 admin'/ #\n",
      "MUTATION_PENALTY @ 23:  all_tables/ 3/ 9 8 admin'/ #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0363 - q_pos_loss: 0.0274 - q_vocab_loss: 0.0089 - q_pos_accuracy: 0.6094 - q_vocab_accuracy: 0.8359\n",
      "SAME_STRING_PENALTY @ 24:  all_tables/ 3/ 9 8 admin'/ #\n",
      "MUTATION_PENALTY @ 24:  all_tables/ 3/ 9 8 admin'/ #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0342 - q_pos_loss: 0.0250 - q_vocab_loss: 0.0092 - q_pos_accuracy: 0.5312 - q_vocab_accuracy: 0.7969\n",
      "SAME_STRING_PENALTY @ 25:  all_tables/ 3/ 9 8 admin'/ #\n",
      "MUTATION_PENALTY @ 25:  all_tables/ 3/ 9 8 admin'/ #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0354 - q_pos_loss: 0.0272 - q_vocab_loss: 0.0082 - q_pos_accuracy: 0.5312 - q_vocab_accuracy: 0.8281\n",
      "PARSER_PENALTY @ 26:  8/ 3/ 9 8 admin'/ #\n",
      "MUTATION_PENALTY @ 26:  8/ 3/ 9 8 admin'/ #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0350 - q_pos_loss: 0.0263 - q_vocab_loss: 0.0087 - q_pos_accuracy: 0.5547 - q_vocab_accuracy: 0.7734\n",
      "SAME_STRING_PENALTY @ 27:  8/ 3/ 9 8 admin'/ #\n",
      "MUTATION_PENALTY @ 27:  8/ 3/ 9 8 admin'/ #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0337 - q_pos_loss: 0.0253 - q_vocab_loss: 0.0084 - q_pos_accuracy: 0.5469 - q_vocab_accuracy: 0.8047\n",
      "SAME_STRING_PENALTY @ 28:  8/ 3/ 9 8 admin'/ #\n",
      "MUTATION_PENALTY @ 28:  8/ 3/ 9 8 admin'/ #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0348 - q_pos_loss: 0.0267 - q_vocab_loss: 0.0082 - q_pos_accuracy: 0.6328 - q_vocab_accuracy: 0.8359\n",
      "SAME_STRING_PENALTY @ 29:  8/ 3/ 9 8 admin'/ #\n",
      "MUTATION_PENALTY @ 29:  8/ 3/ 9 8 admin'/ #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0334 - q_pos_loss: 0.0252 - q_vocab_loss: 0.0081 - q_pos_accuracy: 0.5234 - q_vocab_accuracy: 0.8906\n",
      "SAME_STRING_PENALTY @ 30:  8/ 3/ 9 8 admin'/ #\n",
      "MUTATION_PENALTY @ 30:  8/ 3/ 9 8 admin'/ #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0302 - q_pos_loss: 0.0222 - q_vocab_loss: 0.0081 - q_pos_accuracy: 0.6406 - q_vocab_accuracy: 0.7891\n",
      "SAME_STRING_PENALTY @ 31:  8/ 3/ 9 8 admin'/ #\n",
      "MUTATION_PENALTY @ 31:  8/ 3/ 9 8 admin'/ #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0329 - q_pos_loss: 0.0246 - q_vocab_loss: 0.0082 - q_pos_accuracy: 0.5703 - q_vocab_accuracy: 0.7734\n",
      "PARSER_PENALTY @ 32:  8/ 3/ 9 8 admin'/ instance\n",
      "MUTATION_PENALTY @ 32:  8/ 3/ 9 8 admin'/ instance\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0335 - q_pos_loss: 0.0249 - q_vocab_loss: 0.0086 - q_pos_accuracy: 0.6094 - q_vocab_accuracy: 0.8281\n",
      "SAME_STRING_PENALTY @ 33:  8/ 3/ 9 8 admin'/ instance\n",
      "MUTATION_PENALTY @ 33:  8/ 3/ 9 8 admin'/ instance\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0347 - q_pos_loss: 0.0269 - q_vocab_loss: 0.0078 - q_pos_accuracy: 0.5234 - q_vocab_accuracy: 0.8984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARSER_PENALTY @ 34:  8/ 3/ 9 8 9/ instance\n",
      "MUTATION_PENALTY @ 34:  8/ 3/ 9 8 9/ instance\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0322 - q_pos_loss: 0.0239 - q_vocab_loss: 0.0082 - q_pos_accuracy: 0.5938 - q_vocab_accuracy: 0.8203\n",
      "SAME_STRING_PENALTY @ 35:  8/ 3/ 9 8 9/ instance\n",
      "MUTATION_PENALTY @ 35:  8/ 3/ 9 8 9/ instance\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0335 - q_pos_loss: 0.0257 - q_vocab_loss: 0.0079 - q_pos_accuracy: 0.5234 - q_vocab_accuracy: 0.7891\n",
      "SAME_STRING_PENALTY @ 36:  8/ 3/ 9 8 9/ instance\n",
      "MUTATION_PENALTY @ 36:  8/ 3/ 9 8 9/ instance\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0314 - q_pos_loss: 0.0239 - q_vocab_loss: 0.0075 - q_pos_accuracy: 0.5469 - q_vocab_accuracy: 0.8203\n",
      "PARSER_PENALTY @ 37:  8/ 3/ 9 8 9/ instance #\n",
      "MUTATION_PENALTY @ 37:  8/ 3/ 9 8 9/ instance #\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0302 - q_pos_loss: 0.0221 - q_vocab_loss: 0.0081 - q_pos_accuracy: 0.6328 - q_vocab_accuracy: 0.9297\n",
      "PARSER_PENALTY @ 38:  8/ 3/ 9 8 9/ instance # users\n",
      "MUTATION_PENALTY @ 38:  8/ 3/ 9 8 9/ instance # users\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0305 - q_pos_loss: 0.0236 - q_vocab_loss: 0.0069 - q_pos_accuracy: 0.5234 - q_vocab_accuracy: 0.8906\n",
      "SAME_STRING_PENALTY @ 39:  8/ 3/ 9 8 9/ instance # users\n",
      "MUTATION_PENALTY @ 39:  8/ 3/ 9 8 9/ instance # users\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0302 - q_pos_loss: 0.0226 - q_vocab_loss: 0.0076 - q_pos_accuracy: 0.5625 - q_vocab_accuracy: 0.9062\n",
      "PARSER_PENALTY @ 40:  8/ 3/ 9 8 9/ banner # users\n",
      "MUTATION_PENALTY @ 40:  8/ 3/ 9 8 9/ banner # users\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0304 - q_pos_loss: 0.0231 - q_vocab_loss: 0.0073 - q_pos_accuracy: 0.6562 - q_vocab_accuracy: 0.8906\n",
      "PARSER_PENALTY @ 41:  8/ 3/ 9 8 9/ union # users\n",
      "MUTATION_PENALTY @ 41:  8/ 3/ 9 8 9/ union # users\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0320 - q_pos_loss: 0.0249 - q_vocab_loss: 0.0071 - q_pos_accuracy: 0.5781 - q_vocab_accuracy: 0.8984\n",
      "PARSER_PENALTY @ 42:  8/ 3/ 9 8 9/ 6 # users\n",
      "MUTATION_PENALTY @ 42:  8/ 3/ 9 8 9/ 6 # users\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0307 - q_pos_loss: 0.0236 - q_vocab_loss: 0.0071 - q_pos_accuracy: 0.6094 - q_vocab_accuracy: 0.8906\n",
      "MUTATION_PENALTY @ 43:  8/ 3/ 9 or 9/ 6 # users\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0325 - q_pos_loss: 0.0247 - q_vocab_loss: 0.0078 - q_pos_accuracy: 0.6562 - q_vocab_accuracy: 0.8359\n",
      "MUTATION_PENALTY @ 44:  8/ 3/ 9 or 9/ 6 # users --\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0285 - q_pos_loss: 0.0210 - q_vocab_loss: 0.0075 - q_pos_accuracy: 0.5938 - q_vocab_accuracy: 0.8672\n",
      "PARSER_PENALTY @ 45:  8/ 3/ 9 or 9/ 6 ) users --\n",
      "MUTATION_PENALTY @ 45:  8/ 3/ 9 or 9/ 6 ) users --\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0295 - q_pos_loss: 0.0222 - q_vocab_loss: 0.0073 - q_pos_accuracy: 0.5859 - q_vocab_accuracy: 0.9141\n",
      "SAME_STRING_PENALTY @ 46:  8/ 3/ 9 or 9/ 6 ) users --\n",
      "MUTATION_PENALTY @ 46:  8/ 3/ 9 or 9/ 6 ) users --\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0301 - q_pos_loss: 0.0231 - q_vocab_loss: 0.0070 - q_pos_accuracy: 0.5547 - q_vocab_accuracy: 0.9609\n",
      "PARSER_PENALTY @ 47:  dual/ 3/ 9 or 9/ 6 ) users --\n",
      "MUTATION_PENALTY @ 47:  dual/ 3/ 9 or 9/ 6 ) users --\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0277 - q_pos_loss: 0.0202 - q_vocab_loss: 0.0075 - q_pos_accuracy: 0.5469 - q_vocab_accuracy: 0.8984\n",
      "PARSER_PENALTY @ 48:  admin 3/ 9 or 9/ 6 ) users --\n",
      "MUTATION_PENALTY @ 48:  admin 3/ 9 or 9/ 6 ) users --\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0278 - q_pos_loss: 0.0208 - q_vocab_loss: 0.0070 - q_pos_accuracy: 0.6875 - q_vocab_accuracy: 0.8984\n",
      "SAME_STRING_PENALTY @ 49:  admin 3/ 9 or 9/ 6 ) users --\n",
      "MUTATION_PENALTY @ 49:  admin 3/ 9 or 9/ 6 ) users --\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0263 - q_pos_loss: 0.0197 - q_vocab_loss: 0.0065 - q_pos_accuracy: 0.6484 - q_vocab_accuracy: 0.8359\n",
      "PARSER_PENALTY @ 50:  admin 3/ 9 or 9/ version/ ) users --\n",
      "MUTATION_PENALTY @ 50:  admin 3/ 9 or 9/ version/ ) users --\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0294 - q_pos_loss: 0.0221 - q_vocab_loss: 0.0074 - q_pos_accuracy: 0.5938 - q_vocab_accuracy: 0.8672\n",
      "PARSER_PENALTY @ 51:  admin 3/ 9 1=1/ 9/ version/ ) users --\n",
      "MUTATION_PENALTY @ 51:  admin 3/ 9 1=1/ 9/ version/ ) users --\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0279 - q_pos_loss: 0.0210 - q_vocab_loss: 0.0070 - q_pos_accuracy: 0.5312 - q_vocab_accuracy: 0.8828\n",
      "SAME_STRING_PENALTY @ 52:  admin 3/ 9 1=1/ 9/ version/ ) users --\n",
      "MUTATION_PENALTY @ 52:  admin 3/ 9 1=1/ 9/ version/ ) users --\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0271 - q_pos_loss: 0.0202 - q_vocab_loss: 0.0069 - q_pos_accuracy: 0.5469 - q_vocab_accuracy: 0.8516\n",
      "PARSER_PENALTY @ 53:  admin 3/ 9 1=1/ 9/ version/ ) 1=1/ --\n",
      "MUTATION_PENALTY @ 53:  admin 3/ 9 1=1/ 9/ version/ ) 1=1/ --\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0278 - q_pos_loss: 0.0204 - q_vocab_loss: 0.0074 - q_pos_accuracy: 0.6016 - q_vocab_accuracy: 0.7812\n",
      "PARSER_PENALTY @ 54:  , 3/ 9 1=1/ 9/ version/ ) 1=1/ --\n",
      "MUTATION_PENALTY @ 54:  , 3/ 9 1=1/ 9/ version/ ) 1=1/ --\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0266 - q_pos_loss: 0.0196 - q_vocab_loss: 0.0070 - q_pos_accuracy: 0.6172 - q_vocab_accuracy: 0.8203\n",
      "PARSER_PENALTY @ 55:  , 3/ 9 1=1/ banner version/ ) 1=1/ --\n",
      "MUTATION_PENALTY @ 55:  , 3/ 9 1=1/ banner version/ ) 1=1/ --\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0265 - q_pos_loss: 0.0196 - q_vocab_loss: 0.0069 - q_pos_accuracy: 0.6328 - q_vocab_accuracy: 0.7578\n",
      "PARSER_PENALTY @ 56:  , 3/ 9 1=1/ banner version/ ) 1=1/ )\n",
      "MUTATION_PENALTY @ 56:  , 3/ 9 1=1/ banner version/ ) 1=1/ )\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0271 - q_pos_loss: 0.0203 - q_vocab_loss: 0.0068 - q_pos_accuracy: 0.5703 - q_vocab_accuracy: 0.7109\n",
      "PARSER_PENALTY @ 57:  , 3/ 9 1=1/ ; version/ ) 1=1/ )\n",
      "MUTATION_PENALTY @ 57:  , 3/ 9 1=1/ ; version/ ) 1=1/ )\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0248 - q_pos_loss: 0.0180 - q_vocab_loss: 0.0068 - q_pos_accuracy: 0.6172 - q_vocab_accuracy: 0.7969\n",
      "PARSER_PENALTY @ 58:  , 3/ 9 1=1/ ; or ) 1=1/ )\n",
      "MUTATION_PENALTY @ 58:  , 3/ 9 1=1/ ; or ) 1=1/ )\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0254 - q_pos_loss: 0.0185 - q_vocab_loss: 0.0069 - q_pos_accuracy: 0.6172 - q_vocab_accuracy: 0.6562\n",
      "PARSER_PENALTY @ 59:  , 3/ 9 1=1/ ; or ) 1=1/ ) 9\n",
      "MUTATION_PENALTY @ 59:  , 3/ 9 1=1/ ; or ) 1=1/ ) 9\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0257 - q_pos_loss: 0.0189 - q_vocab_loss: 0.0068 - q_pos_accuracy: 0.6562 - q_vocab_accuracy: 0.7422\n",
      "PARSER_PENALTY @ 60:  , 3/ 9 all_tables/ ; or ) 1=1/ ) 9\n",
      "MUTATION_PENALTY @ 60:  , 3/ 9 all_tables/ ; or ) 1=1/ ) 9\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0263 - q_pos_loss: 0.0204 - q_vocab_loss: 0.0060 - q_pos_accuracy: 0.6328 - q_vocab_accuracy: 0.7266\n",
      "PARSER_PENALTY @ 61:  , 3/ 9 all_tables/ ; or ) 1=1/ ) banner\n",
      "MUTATION_PENALTY @ 61:  , 3/ 9 all_tables/ ; or ) 1=1/ ) banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0255 - q_pos_loss: 0.0189 - q_vocab_loss: 0.0066 - q_pos_accuracy: 0.6250 - q_vocab_accuracy: 0.8281\n",
      "PARSER_PENALTY @ 62:  , 3/ 9 7 ; or ) 1=1/ ) banner\n",
      "MUTATION_PENALTY @ 62:  , 3/ 9 7 ; or ) 1=1/ ) banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0244 - q_pos_loss: 0.0177 - q_vocab_loss: 0.0067 - q_pos_accuracy: 0.7109 - q_vocab_accuracy: 0.8203\n",
      "PARSER_PENALTY @ 63:  , 3/ 9 7 ; or select 1=1/ ) banner\n",
      "MUTATION_PENALTY @ 63:  , 3/ 9 7 ; or select 1=1/ ) banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0250 - q_pos_loss: 0.0190 - q_vocab_loss: 0.0059 - q_pos_accuracy: 0.6328 - q_vocab_accuracy: 0.8828\n",
      "PARSER_PENALTY @ 64:  , 3/ 9 4 ; or select 1=1/ ) banner\n",
      "MUTATION_PENALTY @ 64:  , 3/ 9 4 ; or select 1=1/ ) banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0233 - q_pos_loss: 0.0173 - q_vocab_loss: 0.0060 - q_pos_accuracy: 0.5781 - q_vocab_accuracy: 0.9297\n",
      "PARSER_PENALTY @ 65:  , 3/ 9 4 / or select 1=1/ ) banner\n",
      "MUTATION_PENALTY @ 65:  , 3/ 9 4 / or select 1=1/ ) banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0295 - q_pos_loss: 0.0231 - q_vocab_loss: 0.0064 - q_pos_accuracy: 0.6016 - q_vocab_accuracy: 0.9297\n",
      "PARSER_PENALTY @ 66:  , 3/ 9 2 / or select 1=1/ ) banner\n",
      "MUTATION_PENALTY @ 66:  , 3/ 9 2 / or select 1=1/ ) banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0260 - q_pos_loss: 0.0191 - q_vocab_loss: 0.0069 - q_pos_accuracy: 0.6406 - q_vocab_accuracy: 0.9531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAME_STRING_PENALTY @ 67:  , 3/ 9 2 / or select 1=1/ ) banner\n",
      "MUTATION_PENALTY @ 67:  , 3/ 9 2 / or select 1=1/ ) banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0252 - q_pos_loss: 0.0185 - q_vocab_loss: 0.0067 - q_pos_accuracy: 0.5625 - q_vocab_accuracy: 0.9688\n",
      "SAME_STRING_PENALTY @ 68:  , 3/ 9 2 / or select 1=1/ ) banner\n",
      "MUTATION_PENALTY @ 68:  , 3/ 9 2 / or select 1=1/ ) banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0271 - q_pos_loss: 0.0202 - q_vocab_loss: 0.0068 - q_pos_accuracy: 0.5391 - q_vocab_accuracy: 0.9922\n",
      "PARSER_PENALTY @ 69:  , 3/ 9 2 / or union 1=1/ ) banner\n",
      "MUTATION_PENALTY @ 69:  , 3/ 9 2 / or union 1=1/ ) banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0252 - q_pos_loss: 0.0195 - q_vocab_loss: 0.0057 - q_pos_accuracy: 0.5703 - q_vocab_accuracy: 1.0000\n",
      "PARSER_PENALTY @ 70:  , 3/ 9 2 / or union 2 ) banner\n",
      "MUTATION_PENALTY @ 70:  , 3/ 9 2 / or union 2 ) banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0265 - q_pos_loss: 0.0207 - q_vocab_loss: 0.0058 - q_pos_accuracy: 0.5938 - q_vocab_accuracy: 0.9844\n",
      "PARSER_PENALTY @ 71:  , 3/ 9 1'= / or union 2 ) banner\n",
      "MUTATION_PENALTY @ 71:  , 3/ 9 1'= / or union 2 ) banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0254 - q_pos_loss: 0.0198 - q_vocab_loss: 0.0057 - q_pos_accuracy: 0.5859 - q_vocab_accuracy: 1.0000\n",
      "PARSER_PENALTY @ 72:  , 3/ 9 1'= / / union 2 ) banner\n",
      "MUTATION_PENALTY @ 72:  , 3/ 9 1'= / / union 2 ) banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0247 - q_pos_loss: 0.0187 - q_vocab_loss: 0.0060 - q_pos_accuracy: 0.6562 - q_vocab_accuracy: 0.9922\n",
      "PARSER_PENALTY @ 73:  , 3/ 9 1'= 1=1 / union 2 ) banner\n",
      "MUTATION_PENALTY @ 73:  , 3/ 9 1'= 1=1 / union 2 ) banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0214 - q_pos_loss: 0.0157 - q_vocab_loss: 0.0057 - q_pos_accuracy: 0.7031 - q_vocab_accuracy: 1.0000\n",
      "SAME_STRING_PENALTY @ 74:  , 3/ 9 1'= 1=1 / union 2 ) banner\n",
      "MUTATION_PENALTY @ 74:  , 3/ 9 1'= 1=1 / union 2 ) banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0211 - q_pos_loss: 0.0151 - q_vocab_loss: 0.0059 - q_pos_accuracy: 0.6406 - q_vocab_accuracy: 0.9922\n",
      "SAME_STRING_PENALTY @ 75:  , 3/ 9 1'= 1=1 / union 2 ) banner\n",
      "MUTATION_PENALTY @ 75:  , 3/ 9 1'= 1=1 / union 2 ) banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0219 - q_pos_loss: 0.0160 - q_vocab_loss: 0.0059 - q_pos_accuracy: 0.5703 - q_vocab_accuracy: 1.0000\n",
      "PARSER_PENALTY @ 76:  , 3/ 9 1'= 1=1 / -- 2 ) banner\n",
      "MUTATION_PENALTY @ 76:  , 3/ 9 1'= 1=1 / -- 2 ) banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0243 - q_pos_loss: 0.0180 - q_vocab_loss: 0.0063 - q_pos_accuracy: 0.6172 - q_vocab_accuracy: 0.9922\n",
      "PARSER_PENALTY @ 77:  , 3/ admin'/ 1'= 1=1 / -- 2 ) banner\n",
      "MUTATION_PENALTY @ 77:  , 3/ admin'/ 1'= 1=1 / -- 2 ) banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0245 - q_pos_loss: 0.0186 - q_vocab_loss: 0.0060 - q_pos_accuracy: 0.5781 - q_vocab_accuracy: 0.9922\n",
      "PARSER_PENALTY @ 78:  , 3/ admin'/ 1'= 1=1 / -- 2 instance/ banner\n",
      "MUTATION_PENALTY @ 78:  , 3/ admin'/ 1'= 1=1 / -- 2 instance/ banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0236 - q_pos_loss: 0.0181 - q_vocab_loss: 0.0055 - q_pos_accuracy: 0.5859 - q_vocab_accuracy: 1.0000\n",
      "PARSER_PENALTY @ 79:  , 3/ admin'/ 1'= 5/ / -- 2 instance/ banner\n",
      "MUTATION_PENALTY @ 79:  , 3/ admin'/ 1'= 5/ / -- 2 instance/ banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0220 - q_pos_loss: 0.0164 - q_vocab_loss: 0.0056 - q_pos_accuracy: 0.6484 - q_vocab_accuracy: 0.9922\n",
      "PARSER_PENALTY @ 80:  , 3/ admin'/ 1'= 5/ 8/ -- 2 instance/ banner\n",
      "MUTATION_PENALTY @ 80:  , 3/ admin'/ 1'= 5/ 8/ -- 2 instance/ banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0235 - q_pos_loss: 0.0181 - q_vocab_loss: 0.0054 - q_pos_accuracy: 0.5625 - q_vocab_accuracy: 1.0000\n",
      "PARSER_PENALTY @ 81:  , 3/ 9 1'= 5/ 8/ -- 2 instance/ banner\n",
      "MUTATION_PENALTY @ 81:  , 3/ 9 1'= 5/ 8/ -- 2 instance/ banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0231 - q_pos_loss: 0.0172 - q_vocab_loss: 0.0059 - q_pos_accuracy: 0.5312 - q_vocab_accuracy: 0.9922\n",
      "PARSER_PENALTY @ 82:  , 3/ 9 1'= 5/ 8/ -- 2 6/ banner\n",
      "MUTATION_PENALTY @ 82:  , 3/ 9 1'= 5/ 8/ -- 2 6/ banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0213 - q_pos_loss: 0.0156 - q_vocab_loss: 0.0057 - q_pos_accuracy: 0.6875 - q_vocab_accuracy: 1.0000\n",
      "PARSER_PENALTY @ 83:  , 3/ 9 1'= admin'/ 8/ -- 2 6/ banner\n",
      "MUTATION_PENALTY @ 83:  , 3/ 9 1'= admin'/ 8/ -- 2 6/ banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0209 - q_pos_loss: 0.0160 - q_vocab_loss: 0.0049 - q_pos_accuracy: 0.5312 - q_vocab_accuracy: 0.9922\n",
      "PARSER_PENALTY @ 84:  , 3/ 9 1'= admin'/ 8/ / 2 6/ banner\n",
      "MUTATION_PENALTY @ 84:  , 3/ 9 1'= admin'/ 8/ / 2 6/ banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0225 - q_pos_loss: 0.0168 - q_vocab_loss: 0.0057 - q_pos_accuracy: 0.6016 - q_vocab_accuracy: 1.0000\n",
      "PARSER_PENALTY @ 85:  , 3/ 9 1'= @ 8/ / 2 6/ banner\n",
      "MUTATION_PENALTY @ 85:  , 3/ 9 1'= @ 8/ / 2 6/ banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0205 - q_pos_loss: 0.0145 - q_vocab_loss: 0.0060 - q_pos_accuracy: 0.6875 - q_vocab_accuracy: 0.9922\n",
      "PARSER_PENALTY @ 86:  , 3/ 9 1'= @ 8/ / 2 instance banner\n",
      "MUTATION_PENALTY @ 86:  , 3/ 9 1'= @ 8/ / 2 instance banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0239 - q_pos_loss: 0.0181 - q_vocab_loss: 0.0058 - q_pos_accuracy: 0.5859 - q_vocab_accuracy: 0.9922\n",
      "PARSER_PENALTY @ 87:  , 3/ 9 1'= instance/ 8/ / 2 instance banner\n",
      "MUTATION_PENALTY @ 87:  , 3/ 9 1'= instance/ 8/ / 2 instance banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0229 - q_pos_loss: 0.0171 - q_vocab_loss: 0.0058 - q_pos_accuracy: 0.5703 - q_vocab_accuracy: 0.9922\n",
      "PARSER_PENALTY @ 88:  , 3/ 9 6 instance/ 8/ / 2 instance banner\n",
      "MUTATION_PENALTY @ 88:  , 3/ 9 6 instance/ 8/ / 2 instance banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0248 - q_pos_loss: 0.0195 - q_vocab_loss: 0.0053 - q_pos_accuracy: 0.6094 - q_vocab_accuracy: 1.0000\n",
      "PARSER_PENALTY @ 89:  , 3/ 9 v instance/ 8/ / 2 instance banner\n",
      "MUTATION_PENALTY @ 89:  , 3/ 9 v instance/ 8/ / 2 instance banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0216 - q_pos_loss: 0.0160 - q_vocab_loss: 0.0057 - q_pos_accuracy: 0.6562 - q_vocab_accuracy: 0.9922\n",
      "PARSER_PENALTY @ 90:  , 3/ 9 v instance/ 8/ / 2 instance password\n",
      "MUTATION_PENALTY @ 90:  , 3/ 9 v instance/ 8/ / 2 instance password\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0233 - q_pos_loss: 0.0181 - q_vocab_loss: 0.0052 - q_pos_accuracy: 0.5156 - q_vocab_accuracy: 1.0000\n",
      "PARSER_PENALTY @ 91:  , instance/ 9 v instance/ 8/ / 2 instance password\n",
      "MUTATION_PENALTY @ 91:  , instance/ 9 v instance/ 8/ / 2 instance password\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0221 - q_pos_loss: 0.0165 - q_vocab_loss: 0.0056 - q_pos_accuracy: 0.6094 - q_vocab_accuracy: 0.9844\n",
      "PARSER_PENALTY @ 92:  , instance/ 9 v instance/ 8/ user/ 2 instance password\n",
      "MUTATION_PENALTY @ 92:  , instance/ 9 v instance/ 8/ user/ 2 instance password\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0229 - q_pos_loss: 0.0181 - q_vocab_loss: 0.0048 - q_pos_accuracy: 0.4922 - q_vocab_accuracy: 1.0000\n",
      "PARSER_PENALTY @ 93:  6/ instance/ 9 v instance/ 8/ user/ 2 instance password\n",
      "MUTATION_PENALTY @ 93:  6/ instance/ 9 v instance/ 8/ user/ 2 instance password\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0234 - q_pos_loss: 0.0178 - q_vocab_loss: 0.0056 - q_pos_accuracy: 0.5312 - q_vocab_accuracy: 0.9922\n",
      "PARSER_PENALTY @ 94:  6/ instance/ 3 v instance/ 8/ user/ 2 instance password\n",
      "MUTATION_PENALTY @ 94:  6/ instance/ 3 v instance/ 8/ user/ 2 instance password\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0239 - q_pos_loss: 0.0187 - q_vocab_loss: 0.0052 - q_pos_accuracy: 0.6641 - q_vocab_accuracy: 0.9922\n",
      "PARSER_PENALTY @ 95:  6/ 2 3 v instance/ 8/ user/ 2 instance password\n",
      "MUTATION_PENALTY @ 95:  6/ 2 3 v instance/ 8/ user/ 2 instance password\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0222 - q_pos_loss: 0.0173 - q_vocab_loss: 0.0049 - q_pos_accuracy: 0.6016 - q_vocab_accuracy: 0.9922\n",
      "PARSER_PENALTY @ 96:  6/ 2 union v instance/ 8/ user/ 2 instance password\n",
      "MUTATION_PENALTY @ 96:  6/ 2 union v instance/ 8/ user/ 2 instance password\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0210 - q_pos_loss: 0.0157 - q_vocab_loss: 0.0054 - q_pos_accuracy: 0.5547 - q_vocab_accuracy: 0.9922\n",
      "PARSER_PENALTY @ 97:  6/ 2 admin'/ v instance/ 8/ user/ 2 instance password\n",
      "MUTATION_PENALTY @ 97:  6/ 2 admin'/ v instance/ 8/ user/ 2 instance password\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0218 - q_pos_loss: 0.0166 - q_vocab_loss: 0.0053 - q_pos_accuracy: 0.6016 - q_vocab_accuracy: 0.9922\n",
      "PARSER_PENALTY @ 98:  6/ 2 admin'/ v instance/ user/ user/ 2 instance password\n",
      "MUTATION_PENALTY @ 98:  6/ 2 admin'/ v instance/ user/ user/ 2 instance password\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0202 - q_pos_loss: 0.0151 - q_vocab_loss: 0.0051 - q_pos_accuracy: 0.6562 - q_vocab_accuracy: 0.9844\n",
      "PARSER_PENALTY @ 99:  6/ 2 admin'/ [ instance/ user/ user/ 2 instance password\n",
      "MUTATION_PENALTY @ 99:  6/ 2 admin'/ [ instance/ user/ user/ 2 instance password\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0223 - q_pos_loss: 0.0172 - q_vocab_loss: 0.0051 - q_pos_accuracy: 0.5391 - q_vocab_accuracy: 1.0000\n",
      "SAME_STRING_PENALTY @ 100:  6/ 2 admin'/ [ instance/ user/ user/ 2 instance password\n",
      "MUTATION_PENALTY @ 100:  6/ 2 admin'/ [ instance/ user/ user/ 2 instance password\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0221 - q_pos_loss: 0.0169 - q_vocab_loss: 0.0052 - q_pos_accuracy: 0.5469 - q_vocab_accuracy: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|2                                                                        | 3/1000 [01:21<6:53:35, 24.89s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUTATION_PENALTY @ 1:  ' or ' 1'= ' 1 ' -- --\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0237 - q_pos_loss: 0.0180 - q_vocab_loss: 0.0056 - q_pos_accuracy: 0.5938 - q_vocab_accuracy: 0.9922\n",
      "PARSER_PENALTY @ 2:  ' or ' 1'= or 1 ' -- --\n",
      "MUTATION_PENALTY @ 2:  ' or ' 1'= or 1 ' -- --\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0208 - q_pos_loss: 0.0154 - q_vocab_loss: 0.0054 - q_pos_accuracy: 0.5156 - q_vocab_accuracy: 0.9922\n",
      "PARSER_PENALTY @ 3:  ' or ' 1'= or 1 ' 4/ --\n",
      "MUTATION_PENALTY @ 3:  ' or ' 1'= or 1 ' 4/ --\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 827.6239 - q_pos_loss: 710.9056 - q_vocab_loss: 116.7182 - q_pos_accuracy: 0.5469 - q_vocab_accuracy: 0.9766\n",
      "SAME_STRING_PENALTY @ 4:  ' or ' 1'= or 1 ' 4/ --\n",
      "MUTATION_PENALTY @ 4:  ' or ' 1'= or 1 ' 4/ --\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0216 - q_pos_loss: 0.0160 - q_vocab_loss: 0.0056 - q_pos_accuracy: 0.5859 - q_vocab_accuracy: 0.9766\n",
      "PARSER_PENALTY @ 5:  ' or ' 1'= or 1 ' 4/ -- banner\n",
      "MUTATION_PENALTY @ 5:  ' or ' 1'= or 1 ' 4/ -- banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 827.2475 - q_pos_loss: 710.5543 - q_vocab_loss: 116.6932 - q_pos_accuracy: 0.7500 - q_vocab_accuracy: 0.9844\n",
      "PARSER_PENALTY @ 6:  ' or ' 1'= or 1 $ 4/ -- banner\n",
      "MUTATION_PENALTY @ 6:  ' or ' 1'= or 1 $ 4/ -- banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 826.5861 - q_pos_loss: 709.9159 - q_vocab_loss: 116.6702 - q_pos_accuracy: 0.8516 - q_vocab_accuracy: 0.9844\n",
      "SAME_STRING_PENALTY @ 7:  ' or ' 1'= or 1 $ 4/ -- banner\n",
      "MUTATION_PENALTY @ 7:  ' or ' 1'= or 1 $ 4/ -- banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 826.3672 - q_pos_loss: 709.7100 - q_vocab_loss: 116.6572 - q_pos_accuracy: 0.9062 - q_vocab_accuracy: 0.9844\n",
      "PARSER_PENALTY @ 8:  ' or ' 1'= or dual/ $ 4/ -- banner\n",
      "MUTATION_PENALTY @ 8:  ' or ' 1'= or dual/ $ 4/ -- banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 826.1011 - q_pos_loss: 709.4550 - q_vocab_loss: 116.6461 - q_pos_accuracy: 0.9219 - q_vocab_accuracy: 0.9844\n",
      "PARSER_PENALTY @ 9:  ' or ' 1'= or dual/ 3 4/ -- banner\n",
      "MUTATION_PENALTY @ 9:  ' or ' 1'= or dual/ 3 4/ -- banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 825.9279 - q_pos_loss: 709.2996 - q_vocab_loss: 116.6283 - q_pos_accuracy: 0.9062 - q_vocab_accuracy: 0.9609\n",
      "PARSER_PENALTY @ 10:  ' or ' * or dual/ 3 4/ -- banner\n",
      "MUTATION_PENALTY @ 10:  ' or ' * or dual/ 3 4/ -- banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0517 - q_pos_loss: 0.0451 - q_vocab_loss: 0.0067 - q_pos_accuracy: 0.9141 - q_vocab_accuracy: 0.7969\n",
      "PARSER_PENALTY @ 11:  ' or / * or dual/ 3 4/ -- banner\n",
      "MUTATION_PENALTY @ 11:  ' or / * or dual/ 3 4/ -- banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 824.0938 - q_pos_loss: 707.5143 - q_vocab_loss: 116.5795 - q_pos_accuracy: 0.8516 - q_vocab_accuracy: 0.9062\n",
      "PARSER_PENALTY @ 12:  ' or / 9/ or dual/ 3 4/ -- banner\n",
      "MUTATION_PENALTY @ 12:  ' or / 9/ or dual/ 3 4/ -- banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 823.5594 - q_pos_loss: 707.0408 - q_vocab_loss: 116.5186 - q_pos_accuracy: 0.9062 - q_vocab_accuracy: 0.9688\n",
      "PARSER_PENALTY @ 13:  ' or / 9/ or dual/ 3 4/ instance banner\n",
      "MUTATION_PENALTY @ 13:  ' or / 9/ or dual/ 3 4/ instance banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.3620 - q_pos_loss: 0.3507 - q_vocab_loss: 0.0113 - q_pos_accuracy: 0.9062 - q_vocab_accuracy: 0.9844\n",
      "PARSER_PENALTY @ 14:  ' or / user/ or dual/ 3 4/ instance banner\n",
      "MUTATION_PENALTY @ 14:  ' or / user/ or dual/ 3 4/ instance banner\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.6805 - q_pos_loss: 0.6626 - q_vocab_loss: 0.0179 - q_pos_accuracy: 0.8906 - q_vocab_accuracy: 0.9844\n",
      "PARSER_PENALTY @ 15:  ' or / user/ or dual/ 3 4/ instance 6/\n",
      "MUTATION_PENALTY @ 15:  ' or / user/ or dual/ 3 4/ instance 6/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.5213 - q_pos_loss: 0.5021 - q_vocab_loss: 0.0192 - q_pos_accuracy: 0.8906 - q_vocab_accuracy: 0.9922\n",
      "SAME_STRING_PENALTY @ 16:  ' or / user/ or dual/ 3 4/ instance 6/\n",
      "MUTATION_PENALTY @ 16:  ' or / user/ or dual/ 3 4/ instance 6/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.3453 - q_pos_loss: 0.3258 - q_vocab_loss: 0.0195 - q_pos_accuracy: 0.8906 - q_vocab_accuracy: 0.9453\n",
      "PARSER_PENALTY @ 17:  ' or / user/ or dual/ 3 4/ dual/ 6/\n",
      "MUTATION_PENALTY @ 17:  ' or / user/ or dual/ 3 4/ dual/ 6/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.1599 - q_pos_loss: 0.1498 - q_vocab_loss: 0.0101 - q_pos_accuracy: 0.7969 - q_vocab_accuracy: 0.9062\n",
      "PARSER_PENALTY @ 18:  ' or / user/ or or 3 4/ dual/ 6/\n",
      "MUTATION_PENALTY @ 18:  ' or / user/ or or 3 4/ dual/ 6/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.1570 - q_pos_loss: 0.1480 - q_vocab_loss: 0.0090 - q_pos_accuracy: 0.8750 - q_vocab_accuracy: 0.7812\n",
      "PARSER_PENALTY @ 19:  ' or / 6/ or or 3 4/ dual/ 6/\n",
      "MUTATION_PENALTY @ 19:  ' or / 6/ or or 3 4/ dual/ 6/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.1183 - q_pos_loss: 0.1117 - q_vocab_loss: 0.0066 - q_pos_accuracy: 0.8359 - q_vocab_accuracy: 0.6016\n",
      "SAME_STRING_PENALTY @ 20:  ' or / 6/ or or 3 4/ dual/ 6/\n",
      "MUTATION_PENALTY @ 20:  ' or / 6/ or or 3 4/ dual/ 6/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 819.5991 - q_pos_loss: 703.2350 - q_vocab_loss: 116.3640 - q_pos_accuracy: 0.7266 - q_vocab_accuracy: 0.6172\n",
      "PARSER_PENALTY @ 21:  ' or @ 6/ or or 3 4/ dual/ 6/\n",
      "MUTATION_PENALTY @ 21:  ' or @ 6/ or or 3 4/ dual/ 6/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 816.1070 - q_pos_loss: 699.8571 - q_vocab_loss: 116.2500 - q_pos_accuracy: 0.6953 - q_vocab_accuracy: 0.6016\n",
      "PARSER_PENALTY @ 22:  ' or @ 6/ or or 3 4 dual/ 6/\n",
      "MUTATION_PENALTY @ 22:  ' or @ 6/ or or 3 4 dual/ 6/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 816.1097 - q_pos_loss: 699.9726 - q_vocab_loss: 116.1371 - q_pos_accuracy: 0.7578 - q_vocab_accuracy: 0.6094\n",
      "SAME_STRING_PENALTY @ 23:  ' or @ 6/ or or 3 4 dual/ 6/\n",
      "MUTATION_PENALTY @ 23:  ' or @ 6/ or or 3 4 dual/ 6/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.2980 - q_pos_loss: 0.2825 - q_vocab_loss: 0.0155 - q_pos_accuracy: 0.7734 - q_vocab_accuracy: 0.4688\n",
      "PARSER_PENALTY @ 24:  ' or , 6/ or or 3 4 dual/ 6/\n",
      "MUTATION_PENALTY @ 24:  ' or , 6/ or or 3 4 dual/ 6/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.3402 - q_pos_loss: 0.3256 - q_vocab_loss: 0.0147 - q_pos_accuracy: 0.7031 - q_vocab_accuracy: 0.5469\n",
      "PARSER_PENALTY @ 25:  ' or , 6/ or or 3 ; dual/ 6/\n",
      "MUTATION_PENALTY @ 25:  ' or , 6/ or or 3 ; dual/ 6/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 814.4928 - q_pos_loss: 698.6362 - q_vocab_loss: 115.8566 - q_pos_accuracy: 0.7266 - q_vocab_accuracy: 0.5703\n",
      "PARSER_PENALTY @ 26:  ' or , order or or 3 ; dual/ 6/\n",
      "MUTATION_PENALTY @ 26:  ' or , order or or 3 ; dual/ 6/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.8351 - q_pos_loss: 0.7971 - q_vocab_loss: 0.0381 - q_pos_accuracy: 0.7031 - q_vocab_accuracy: 0.5938\n",
      "PARSER_PENALTY @ 27:  ' or , order 1/ or 3 ; dual/ 6/\n",
      "MUTATION_PENALTY @ 27:  ' or , order 1/ or 3 ; dual/ 6/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.6765 - q_pos_loss: 0.6347 - q_vocab_loss: 0.0418 - q_pos_accuracy: 0.7031 - q_vocab_accuracy: 0.6172\n",
      "SAME_STRING_PENALTY @ 28:  ' or , order 1/ or 3 ; dual/ 6/\n",
      "MUTATION_PENALTY @ 28:  ' or , order 1/ or 3 ; dual/ 6/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.6120 - q_pos_loss: 0.5762 - q_vocab_loss: 0.0358 - q_pos_accuracy: 0.7109 - q_vocab_accuracy: 0.6250\n",
      "PARSER_PENALTY @ 29:  ' or , order 1/ or 3 @ dual/ 6/\n",
      "MUTATION_PENALTY @ 29:  ' or , order 1/ or 3 @ dual/ 6/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.7727 - q_pos_loss: 0.7180 - q_vocab_loss: 0.0548 - q_pos_accuracy: 0.6250 - q_vocab_accuracy: 0.6797\n",
      "PARSER_PENALTY @ 30:  ' or , order 1/ or 3 password dual/ 6/\n",
      "MUTATION_PENALTY @ 30:  ' or , order 1/ or 3 password dual/ 6/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.3652 - q_pos_loss: 0.3413 - q_vocab_loss: 0.0239 - q_pos_accuracy: 0.6641 - q_vocab_accuracy: 0.6797\n",
      "PARSER_PENALTY @ 31:  ' instance/ , order 1/ or 3 password dual/ 6/\n",
      "MUTATION_PENALTY @ 31:  ' instance/ , order 1/ or 3 password dual/ 6/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 800.5886 - q_pos_loss: 685.1938 - q_vocab_loss: 115.3947 - q_pos_accuracy: 0.6875 - q_vocab_accuracy: 0.7266\n",
      "PARSER_PENALTY @ 32:  ' instance/ , dual/ 1/ or 3 password dual/ 6/\n",
      "MUTATION_PENALTY @ 32:  ' instance/ , dual/ 1/ or 3 password dual/ 6/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 803.2981 - q_pos_loss: 688.0263 - q_vocab_loss: 115.2718 - q_pos_accuracy: 0.5312 - q_vocab_accuracy: 0.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARSER_PENALTY @ 33:  ' instance/ , dual/ 1/ or 3 password dual/\n",
      "MUTATION_PENALTY @ 33:  ' instance/ , dual/ 1/ or 3 password dual/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.3621 - q_pos_loss: 0.3388 - q_vocab_loss: 0.0233 - q_pos_accuracy: 0.5469 - q_vocab_accuracy: 0.7266\n",
      "SAME_STRING_PENALTY @ 34:  ' instance/ , dual/ 1/ or 3 password dual/\n",
      "MUTATION_PENALTY @ 34:  ' instance/ , dual/ 1/ or 3 password dual/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.8161 - q_pos_loss: 0.7132 - q_vocab_loss: 0.1029 - q_pos_accuracy: 0.5547 - q_vocab_accuracy: 0.7500\n",
      "PARSER_PENALTY @ 35:  ' instance/ , dual/ 1/ or 3 password dual/ email\n",
      "MUTATION_PENALTY @ 35:  ' instance/ , dual/ 1/ or 3 password dual/ email\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 792.3799 - q_pos_loss: 676.9836 - q_vocab_loss: 115.3963 - q_pos_accuracy: 0.5859 - q_vocab_accuracy: 0.8516\n",
      "PARSER_PENALTY @ 36:  ' instance/ , dual/ 1/ or 3 password union email\n",
      "MUTATION_PENALTY @ 36:  ' instance/ , dual/ 1/ or 3 password union email\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 1.3287 - q_pos_loss: 1.2306 - q_vocab_loss: 0.0982 - q_pos_accuracy: 0.5703 - q_vocab_accuracy: 0.8516\n",
      "PARSER_PENALTY @ 37:  ' instance/ , dual/ 1/ or 3 password union 8/\n",
      "MUTATION_PENALTY @ 37:  ' instance/ , dual/ 1/ or 3 password union 8/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 1.3520 - q_pos_loss: 1.2647 - q_vocab_loss: 0.0873 - q_pos_accuracy: 0.5781 - q_vocab_accuracy: 0.6953\n",
      "PARSER_PENALTY @ 38:  ' instance/ 9/ dual/ 1/ or 3 password union 8/\n",
      "MUTATION_PENALTY @ 38:  ' instance/ 9/ dual/ 1/ or 3 password union 8/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 1.5897 - q_pos_loss: 1.4779 - q_vocab_loss: 0.1118 - q_pos_accuracy: 0.6484 - q_vocab_accuracy: 0.7031\n",
      "PARSER_PENALTY @ 39:  ' instance/ 9/ dual/ 1'= or 3 password union 8/\n",
      "MUTATION_PENALTY @ 39:  ' instance/ 9/ dual/ 1'= or 3 password union 8/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 1.8528 - q_pos_loss: 1.7499 - q_vocab_loss: 0.1029 - q_pos_accuracy: 0.5781 - q_vocab_accuracy: 0.7656\n",
      "PARSER_PENALTY @ 40:  ' instance/ 9/ ' 1'= or 3 password union 8/\n",
      "MUTATION_PENALTY @ 40:  ' instance/ 9/ ' 1'= or 3 password union 8/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 1.9216 - q_pos_loss: 1.8024 - q_vocab_loss: 0.1192 - q_pos_accuracy: 0.5781 - q_vocab_accuracy: 0.8047\n",
      "SAME_STRING_PENALTY @ 41:  ' instance/ 9/ ' 1'= or 3 password union 8/\n",
      "MUTATION_PENALTY @ 41:  ' instance/ 9/ ' 1'= or 3 password union 8/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.2644 - q_pos_loss: 0.2342 - q_vocab_loss: 0.0302 - q_pos_accuracy: 0.6406 - q_vocab_accuracy: 0.7812\n",
      "PARSER_PENALTY @ 42:  ' instance/ 9/ ' 1'= or 5 password union 8/\n",
      "MUTATION_PENALTY @ 42:  ' instance/ 9/ ' 1'= or 5 password union 8/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 1.2297 - q_pos_loss: 1.1533 - q_vocab_loss: 0.0764 - q_pos_accuracy: 0.5391 - q_vocab_accuracy: 0.7969\n",
      "PARSER_PENALTY @ 43:  ' instance/ 9/ ' select or 5 password union 8/\n",
      "MUTATION_PENALTY @ 43:  ' instance/ 9/ ' select or 5 password union 8/\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 784.1390 - q_pos_loss: 669.3692 - q_vocab_loss: 114.7698 - q_pos_accuracy: 0.6875 - q_vocab_accuracy: 0.8906\n",
      "PARSER_PENALTY @ 44:  ' instance/ 9/ ' select or 5 password union order\n",
      "MUTATION_PENALTY @ 44:  ' instance/ 9/ ' select or 5 password union order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.4137 - q_pos_loss: 0.3748 - q_vocab_loss: 0.0389 - q_pos_accuracy: 0.6797 - q_vocab_accuracy: 0.8750\n",
      "PARSER_PENALTY @ 45:  ' instance/ 9/ ' select or 6/ password union order\n",
      "MUTATION_PENALTY @ 45:  ' instance/ 9/ ' select or 6/ password union order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.4962 - q_pos_loss: 0.4710 - q_vocab_loss: 0.0252 - q_pos_accuracy: 0.7188 - q_vocab_accuracy: 0.8828\n",
      "PARSER_PENALTY @ 46:  ' instance/ 9/ ' select 4/ 6/ password union order\n",
      "MUTATION_PENALTY @ 46:  ' instance/ 9/ ' select 4/ 6/ password union order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.1381 - q_pos_loss: 0.1213 - q_vocab_loss: 0.0169 - q_pos_accuracy: 0.7031 - q_vocab_accuracy: 0.9531\n",
      "PARSER_PENALTY @ 47:  ' instance/ 6 ' select 4/ 6/ password union order\n",
      "MUTATION_PENALTY @ 47:  ' instance/ 6 ' select 4/ 6/ password union order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0687 - q_pos_loss: 0.0542 - q_vocab_loss: 0.0145 - q_pos_accuracy: 0.7109 - q_vocab_accuracy: 0.9141\n",
      "MUTATION_PENALTY @ 48:  ' # 6 ' select 4/ 6/ password union order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 769.8571 - q_pos_loss: 656.1725 - q_vocab_loss: 113.6846 - q_pos_accuracy: 0.7500 - q_vocab_accuracy: 0.9375\n",
      "MUTATION_PENALTY @ 49:  ' # 6 ' select 1=1/ 6/ password union order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0540 - q_pos_loss: 0.0452 - q_vocab_loss: 0.0088 - q_pos_accuracy: 0.6875 - q_vocab_accuracy: 0.9453\n",
      "MUTATION_PENALTY @ 50:  ' # $ ' select 1=1/ 6/ password union order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0500 - q_pos_loss: 0.0419 - q_vocab_loss: 0.0081 - q_pos_accuracy: 0.6328 - q_vocab_accuracy: 0.9453\n",
      "MUTATION_PENALTY @ 51:  ' # $ 6 select 1=1/ 6/ password union order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.1378 - q_pos_loss: 0.1143 - q_vocab_loss: 0.0235 - q_pos_accuracy: 0.6016 - q_vocab_accuracy: 0.9141\n",
      "MUTATION_PENALTY @ 52:  ' # $ 6 order 1=1/ 6/ password union order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 777.2422 - q_pos_loss: 664.3630 - q_vocab_loss: 112.8792 - q_pos_accuracy: 0.5625 - q_vocab_accuracy: 0.9219\n",
      "MUTATION_PENALTY @ 53:  ' # $ 8/ order 1=1/ 6/ password union order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0322 - q_pos_loss: 0.0258 - q_vocab_loss: 0.0064 - q_pos_accuracy: 0.5000 - q_vocab_accuracy: 0.9688\n",
      "MUTATION_PENALTY @ 54:  ' # $ 8/ order 1=1/ 6/ order union order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.1949 - q_pos_loss: 0.1834 - q_vocab_loss: 0.0115 - q_pos_accuracy: 0.5781 - q_vocab_accuracy: 0.9453\n",
      "MUTATION_PENALTY @ 55:  ' # $ 8/ order 1=1/ 6/ 1/ union order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.1655 - q_pos_loss: 0.1224 - q_vocab_loss: 0.0431 - q_pos_accuracy: 0.4922 - q_vocab_accuracy: 0.9375\n",
      "MUTATION_PENALTY @ 56:  ' # $ 8/ order 1=1/ 6/ 1/ # order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 748.9934 - q_pos_loss: 636.7987 - q_vocab_loss: 112.1947 - q_pos_accuracy: 0.5391 - q_vocab_accuracy: 0.9609\n",
      "SAME_STRING_PENALTY @ 57:  ' # $ 8/ order 1=1/ 6/ 1/ # order\n",
      "MUTATION_PENALTY @ 57:  ' # $ 8/ order 1=1/ 6/ 1/ # order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0535 - q_pos_loss: 0.0469 - q_vocab_loss: 0.0067 - q_pos_accuracy: 0.5547 - q_vocab_accuracy: 0.9297\n",
      "PARSER_PENALTY @ 58:  ' instance/ $ 8/ order 1=1/ 6/ 1/ # order\n",
      "MUTATION_PENALTY @ 58:  ' instance/ $ 8/ order 1=1/ 6/ 1/ # order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.7001 - q_pos_loss: 0.5969 - q_vocab_loss: 0.1033 - q_pos_accuracy: 0.5156 - q_vocab_accuracy: 0.9531\n",
      "PARSER_PENALTY @ 59:  ' instance/ $ 8/ order 1=1/ 3 1/ # order\n",
      "MUTATION_PENALTY @ 59:  ' instance/ $ 8/ order 1=1/ 3 1/ # order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 1.0275 - q_pos_loss: 0.9940 - q_vocab_loss: 0.0335 - q_pos_accuracy: 0.5391 - q_vocab_accuracy: 0.9609\n",
      "PARSER_PENALTY @ 60:  1'= instance/ $ 8/ order 1=1/ 3 1/ # order\n",
      "MUTATION_PENALTY @ 60:  1'= instance/ $ 8/ order 1=1/ 3 1/ # order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 756.9933 - q_pos_loss: 645.2773 - q_vocab_loss: 111.7160 - q_pos_accuracy: 0.5156 - q_vocab_accuracy: 0.9062\n",
      "PARSER_PENALTY @ 61:  v instance/ $ 8/ order 1=1/ 3 1/ # order\n",
      "MUTATION_PENALTY @ 61:  v instance/ $ 8/ order 1=1/ 3 1/ # order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 756.6139 - q_pos_loss: 644.6096 - q_vocab_loss: 112.0043 - q_pos_accuracy: 0.5547 - q_vocab_accuracy: 0.9844\n",
      "PARSER_PENALTY @ 62:  v instance/ 0 8/ order 1=1/ 3 1/ # order\n",
      "MUTATION_PENALTY @ 62:  v instance/ 0 8/ order 1=1/ 3 1/ # order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.1766 - q_pos_loss: 0.1565 - q_vocab_loss: 0.0201 - q_pos_accuracy: 0.4141 - q_vocab_accuracy: 0.9766\n",
      "PARSER_PENALTY @ 63:  v instance/ 0 8/ order 1=1/ 3 union # order\n",
      "MUTATION_PENALTY @ 63:  v instance/ 0 8/ order 1=1/ 3 union # order\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.2085 - q_pos_loss: 0.1851 - q_vocab_loss: 0.0234 - q_pos_accuracy: 0.4766 - q_vocab_accuracy: 0.9766\n",
      "PARSER_PENALTY @ 64:  v instance/ 0 8/ order 1=1/ 3 union # pass\n",
      "MUTATION_PENALTY @ 64:  v instance/ 0 8/ order 1=1/ 3 union # pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128 samples\n",
      "128/128 - 2s - loss: 738.4904 - q_pos_loss: 627.1758 - q_vocab_loss: 111.3145 - q_pos_accuracy: 0.3828 - q_vocab_accuracy: 1.0000\n",
      "SAME_STRING_PENALTY @ 65:  v instance/ 0 8/ order 1=1/ 3 union # pass\n",
      "MUTATION_PENALTY @ 65:  v instance/ 0 8/ order 1=1/ 3 union # pass\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.1845 - q_pos_loss: 0.1174 - q_vocab_loss: 0.0671 - q_pos_accuracy: 0.4531 - q_vocab_accuracy: 0.9922\n",
      "PARSER_PENALTY @ 66:  v instance/ 0 8/ 2 1=1/ 3 union # pass\n",
      "MUTATION_PENALTY @ 66:  v instance/ 0 8/ 2 1=1/ 3 union # pass\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0299 - q_pos_loss: 0.0238 - q_vocab_loss: 0.0062 - q_pos_accuracy: 0.5078 - q_vocab_accuracy: 0.9219\n",
      "PARSER_PENALTY @ 67:  v instance/ 0 1/ 2 1=1/ 3 union # pass\n",
      "MUTATION_PENALTY @ 67:  v instance/ 0 1/ 2 1=1/ 3 union # pass\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.1349 - q_pos_loss: 0.1104 - q_vocab_loss: 0.0245 - q_pos_accuracy: 0.5078 - q_vocab_accuracy: 0.9844\n",
      "PARSER_PENALTY @ 68:  v instance/ 0 1/ 2 1=1/ 3 v # pass\n",
      "MUTATION_PENALTY @ 68:  v instance/ 0 1/ 2 1=1/ 3 v # pass\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 725.4185 - q_pos_loss: 615.0999 - q_vocab_loss: 110.3186 - q_pos_accuracy: 0.4531 - q_vocab_accuracy: 0.9922\n",
      "SAME_STRING_PENALTY @ 69:  v instance/ 0 1/ 2 1=1/ 3 v # pass\n",
      "MUTATION_PENALTY @ 69:  v instance/ 0 1/ 2 1=1/ 3 v # pass\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.1351 - q_pos_loss: 0.0790 - q_vocab_loss: 0.0562 - q_pos_accuracy: 0.5547 - q_vocab_accuracy: 0.9375\n",
      "PARSER_PENALTY @ 70:  v instance/ 0 1/ 8 1=1/ 3 v # pass\n",
      "MUTATION_PENALTY @ 70:  v instance/ 0 1/ 8 1=1/ 3 v # pass\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.2716 - q_pos_loss: 0.2134 - q_vocab_loss: 0.0583 - q_pos_accuracy: 0.5781 - q_vocab_accuracy: 0.9766\n",
      "PARSER_PENALTY @ 71:  v instance/ 0 1/ union 1=1/ 3 v # pass\n",
      "MUTATION_PENALTY @ 71:  v instance/ 0 1/ union 1=1/ 3 v # pass\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 723.5796 - q_pos_loss: 614.1144 - q_vocab_loss: 109.4651 - q_pos_accuracy: 0.5312 - q_vocab_accuracy: 0.9609\n",
      "PARSER_PENALTY @ 72:  v instance/ 0 9 union 1=1/ 3 v # pass\n",
      "MUTATION_PENALTY @ 72:  v instance/ 0 9 union 1=1/ 3 v # pass\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0271 - q_pos_loss: 0.0213 - q_vocab_loss: 0.0058 - q_pos_accuracy: 0.5234 - q_vocab_accuracy: 0.9375\n",
      "PARSER_PENALTY @ 73:  v instance/ 0 9 union 9/ 3 v # pass\n",
      "MUTATION_PENALTY @ 73:  v instance/ 0 9 union 9/ 3 v # pass\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0283 - q_pos_loss: 0.0217 - q_vocab_loss: 0.0065 - q_pos_accuracy: 0.5234 - q_vocab_accuracy: 0.9531\n",
      "PARSER_PENALTY @ 74:  v instance/ 0 user union 9/ 3 v # pass\n",
      "MUTATION_PENALTY @ 74:  v instance/ 0 user union 9/ 3 v # pass\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.2095 - q_pos_loss: 0.1654 - q_vocab_loss: 0.0441 - q_pos_accuracy: 0.4766 - q_vocab_accuracy: 0.9688\n",
      "PARSER_PENALTY @ 75:  v instance/ 0 user union 9/ 3 users # pass\n",
      "MUTATION_PENALTY @ 75:  v instance/ 0 user union 9/ 3 users # pass\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.3862 - q_pos_loss: 0.3263 - q_vocab_loss: 0.0599 - q_pos_accuracy: 0.5078 - q_vocab_accuracy: 0.9219\n",
      "PARSER_PENALTY @ 76:  instance/ instance/ 0 user union 9/ 3 users # pass\n",
      "MUTATION_PENALTY @ 76:  instance/ instance/ 0 user union 9/ 3 users # pass\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.5436 - q_pos_loss: 0.3467 - q_vocab_loss: 0.1969 - q_pos_accuracy: 0.5156 - q_vocab_accuracy: 0.8828\n",
      "PARSER_PENALTY @ 77:  instance/ instance/ 0 0 union 9/ 3 users # pass\n",
      "MUTATION_PENALTY @ 77:  instance/ instance/ 0 0 union 9/ 3 users # pass\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 696.4005 - q_pos_loss: 586.4924 - q_vocab_loss: 109.9081 - q_pos_accuracy: 0.5625 - q_vocab_accuracy: 0.8125\n",
      "SAME_STRING_PENALTY @ 78:  instance/ instance/ 0 0 union 9/ 3 users # pass\n",
      "MUTATION_PENALTY @ 78:  instance/ instance/ 0 0 union 9/ 3 users # pass\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 704.7473 - q_pos_loss: 597.2465 - q_vocab_loss: 107.5008 - q_pos_accuracy: 0.5312 - q_vocab_accuracy: 0.8750\n",
      "PARSER_PENALTY @ 79:  instance/ instance/ 0 0 union 9/ , users # pass\n",
      "MUTATION_PENALTY @ 79:  instance/ instance/ 0 0 union 9/ , users # pass\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0291 - q_pos_loss: 0.0231 - q_vocab_loss: 0.0060 - q_pos_accuracy: 0.5156 - q_vocab_accuracy: 0.7891\n",
      "MUTATION_PENALTY @ 80:  instance/ instance/ 0\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 696.0546 - q_pos_loss: 587.8530 - q_vocab_loss: 108.2015 - q_pos_accuracy: 0.5312 - q_vocab_accuracy: 0.8125\n",
      "PARSER_PENALTY @ 81:  instance/ instance/ 0 union\n",
      "MUTATION_PENALTY @ 81:  instance/ instance/ 0 union\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 0.0248 - q_pos_loss: 0.0196 - q_vocab_loss: 0.0052 - q_pos_accuracy: 0.4453 - q_vocab_accuracy: 0.7500\n",
      "PARSER_PENALTY @ 82:  2/ instance/ 0 union\n",
      "MUTATION_PENALTY @ 82:  2/ instance/ 0 union\n",
      "Train on 128 samples\n",
      "128/128 - 0s - loss: 684.7407 - q_pos_loss: 577.3417 - q_vocab_loss: 107.3990 - q_pos_accuracy: 0.5156 - q_vocab_accuracy: 0.7656\n",
      "SAME_STRING_PENALTY @ 83:  2/ instance/ 0 union\n",
      "MUTATION_PENALTY @ 83:  2/ instance/ 0 union\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|2                                                                       | 3/1000 [01:55<10:37:48, 38.38s/episodes]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-c3bdf248b134>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;31m# At every step update replay memory and train main network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_replay_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_vocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mcurrent_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-a68f54d46bfa>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, terminal_state, step)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;31m# When using target network, query it, otherwise main network should be queried\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mnew_current_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtransition\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtransition\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[0mfuture_qs_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_current_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_vocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\UW_AI\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\UW_AI\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\UW_AI\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\UW_AI\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\UW_AI\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"batch\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\UW_AI\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[1;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m     dataset = dataset.map(\n\u001b[1;32m--> 390\u001b[1;33m         grab_batch, num_parallel_calls=dataset_ops.AUTOTUNE)\n\u001b[0m\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[1;31m# Default optimizations are disabled to avoid the overhead of (unnecessary)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\UW_AI\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[0;32m   1589\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1590\u001b[0m       return ParallelMapDataset(\n\u001b[1;32m-> 1591\u001b[1;33m           self, map_func, num_parallel_calls, preserve_cardinality=True)\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\UW_AI\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[0;32m   3924\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3925\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3926\u001b[1;33m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[0;32m   3927\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[0;32m   3928\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
      "\u001b[1;32m~\\.conda\\envs\\UW_AI\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   3145\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3146\u001b[0m         \u001b[1;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3147\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\UW_AI\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2393\u001b[0m     \u001b[1;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[1;32m-> 2395\u001b[1;33m         *args, **kwargs)\n\u001b[0m\u001b[0;32m   2396\u001b[0m     \u001b[1;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2397\u001b[0m     \u001b[1;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\UW_AI\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2388\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2389\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2390\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\UW_AI\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2703\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2705\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\UW_AI\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2593\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2595\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\UW_AI\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    866\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mfunc_graph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m     func_graph = FuncGraph(name, collections=collections,\n\u001b[1;32m--> 868\u001b[1;33m                            capture_by_value=capture_by_value)\n\u001b[0m\u001b[0;32m    869\u001b[0m   \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFuncGraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\UW_AI\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, collections, capture_by_value)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mouter\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfailing\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mto\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \"\"\"\n\u001b[1;32m--> 184\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFuncGraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\UW_AI\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2807\u001b[0m     \u001b[1;31m# TODO(skyewm): fold as much of the above as possible into the C\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m     \u001b[1;31m# implementation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2809\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scoped_c_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mScopedTFGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2810\u001b[0m     \u001b[1;31m# The C API requires all ops to have shape functions. Disable this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2811\u001b[0m     \u001b[1;31m# requirement (many custom ops do not have shape functions, and we don't\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\UW_AI\\lib\\site-packages\\tensorflow_core\\python\\framework\\c_api_util.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_NewGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = RLFuzzEnv()\n",
    "ep_rewards = [-200]\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "if not os.path.isdir('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "agent = DQNAgent()\n",
    "\n",
    "for episode in tqdm(range(1, EPISODES + 1), ascii=True, unit='episodes'):\n",
    "\n",
    "    # Update tensorboard step every episode #$REM\n",
    "    # agent.tensorboard.step = episode\n",
    "\n",
    "    # Restarting episode - reset episode reward, step number, and env + get current state\n",
    "    episode_reward = 0\n",
    "    step = 1\n",
    "#     if episode == 2:\n",
    "#         current_state = env.reset(succ)\n",
    "#     else:\n",
    "    current_state = env.reset()\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        if np.random.random() > epsilon:\n",
    "            q_values = agent.get_qs(current_state)\n",
    "            action_pos = np.argmax(q_values[0][0])\n",
    "            action_vocab = np.argmax(q_values[1][0])\n",
    "            # action = np.argmax(agent.get_qs(current_state))\n",
    "        else:\n",
    "            action_pos = np.random.randint(0, env.ACTION_SPACE_SIZE_POS)\n",
    "            action_vocab = np.random.randint(0, env.ACTION_SPACE_SIZE_VOCAB)\n",
    "\n",
    "        new_state, reward, done = env.step(action_pos, action_vocab)\n",
    "        episode_reward += reward\n",
    "\n",
    "        # At every step update replay memory and train main network\n",
    "        agent.update_replay_memory((current_state, action_pos, action_vocab, reward, new_state, done))\n",
    "        agent.train(done, step)\n",
    "\n",
    "        current_state = new_state\n",
    "        step += 1\n",
    "\n",
    "    # Logging\n",
    "    ep_rewards.append(episode_reward)\n",
    "    if not episode % AGGREGATE_STATS_EVERY or episode == 1:\n",
    "        average_reward = sum(ep_rewards[-AGGREGATE_STATS_EVERY:])/len(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "        min_reward = min(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "        max_reward = max(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "        \n",
    "        #$REM agent.tensorboard.update_stats(reward_avg=average_reward, reward_min=min_reward, reward_max=max_reward, epsilon=epsilon)\n",
    "\n",
    "        if min_reward > MIN_REWARD:\n",
    "            agent.model.save(f'models/{MODEL_NAME}__{max_reward:_>7.2f}max_{average_reward:_>7.2f}avg_{min_reward:_>7.2f}min__{int(time.time())}.model')\n",
    "\n",
    "    # Decay epsilon\n",
    "    if epsilon > MIN_EPSILON:\n",
    "        epsilon *= EPSILON_DECAY\n",
    "        epsilon = max(MIN_EPSILON, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-exclusion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ModifiedTensorBoard(TensorBoard):\n",
    "\n",
    "#     # Overriding init to set initial step and writer (we want one log file for all .fit() calls)\n",
    "#     def __init__(self, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.step = 1\n",
    "#         self.writer = tf.summary.create_file_writer(self.log_dir)\n",
    "#         self._log_write_dir = self.log_dir\n",
    "\n",
    "#     # Overriding this method to stop creating default log writer\n",
    "#     def set_model(self, model):\n",
    "#         pass\n",
    "\n",
    "#     # Overrided, saves logs with our step number\n",
    "#     # (otherwise every .fit() will start writing from 0th step)\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         self.update_stats(**logs)\n",
    "\n",
    "#     # Overrided\n",
    "#     # We train for one batch only, no need to save anything at epoch end\n",
    "#     def on_batch_end(self, batch, logs=None):\n",
    "#         pass\n",
    "\n",
    "#     # Overrided, so won't close writer\n",
    "#     def on_train_end(self, _):\n",
    "#         pass\n",
    "\n",
    "#     # Custom method for saving own metrics\n",
    "#     # Creates writer, writes custom metrics and closes writer\n",
    "#     def update_stats(self, **stats):\n",
    "#         self._write_logs(stats, self.step)\n",
    "        \n",
    "#     def _write_logs(self, logs, index):\n",
    "#         with self.writer.as_default():\n",
    "#             for name, value in logs.items():\n",
    "#                 tf.summary.scalar(name, value, step=index)\n",
    "#                 self.step += 1\n",
    "#                 self.writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TransformerBlock(layers.Layer):\n",
    "#     def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "#         super(TransformerBlock, self).__init__()\n",
    "#         self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "#         self.ffn = keras.Sequential(\n",
    "#             [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "#         )\n",
    "#         self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "#         self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "#         self.dropout1 = layers.Dropout(rate)\n",
    "#         self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "#     def call(self, inputs, training):\n",
    "#         attn_output = self.att(inputs, inputs)\n",
    "#         attn_output1 = self.dropout1(attn_output, training=training)\n",
    "#         out1 = self.layernorm1(inputs + attn_output1)\n",
    "#         ffn_output = self.ffn(out1)\n",
    "#         ffn_output = self.dropout2(ffn_output, training=training)\n",
    "#         return self.layernorm2(out1 + ffn_output), attn_output\n",
    "    \n",
    "# class TokenAndPositionEmbedding(layers.Layer):\n",
    "#     def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "#         super(TokenAndPositionEmbedding, self).__init__()\n",
    "#         self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "#         self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "#     def call(self, x):\n",
    "#         maxlen = tf.shape(x)[-1]\n",
    "#         positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "#         positions = self.pos_emb(positions)\n",
    "#         x = self.token_emb(x)\n",
    "#         return x + positions\n",
    "\n",
    "# embed_dim = 32  # Embedding size for each token\n",
    "# num_heads = 2  # Number of attention heads\n",
    "# ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "# inputs = Input(shape=(MAX_LENGTH,))\n",
    "# embedding_layer = TokenAndPositionEmbedding(MAX_LENGTH, VOCAB_SIZE, embed_dim)\n",
    "# x = embedding_layer(inputs)\n",
    "# transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "# x, attn_output = transformer_block(x)\n",
    "# x = GlobalAveragePooling1D()(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "# x = Dense(64, activation=\"relu\")(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "\n",
    "# x_pos = Dense(32, activation=\"relu\")(x)\n",
    "# x_pos = Dropout(0.1)(x_pos)\n",
    "# x_pos = Dense(env.ACTION_SPACE_SIZE_POS, activation='linear')(x_pos)\n",
    "\n",
    "# x_vocab = Dense(32, activation=\"relu\")(x)\n",
    "# x_vocab = Dropout(0.1)(x_vocab)\n",
    "# x_vocab = Dense(env.ACTION_SPACE_SIZE_VOCAB, activation='linear')(x_vocab)\n",
    "\n",
    "# model = keras.Model(inputs=inputs, outputs=[x_pos, x_vocab])\n",
    "\n",
    "# model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
